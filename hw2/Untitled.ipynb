{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "done\n",
      "lambda = 1.0:\taccuracy=0.71868\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from urllib.request import urlopen\n",
    "import scipy.optimize\n",
    "import random\n",
    "from math import exp\n",
    "from math import log\n",
    "\n",
    "def parseData(fname):\n",
    "  for l in urlopen(fname):\n",
    "    yield eval(l)\n",
    "\n",
    "print(\"Reading data...\")\n",
    "data = list(parseData(\"http://jmcauley.ucsd.edu/cse190/data/beer/beer_50000.json\"))\n",
    "print(\"done\")\n",
    "\n",
    "def feature(datum):\n",
    "  feat = [1, datum['review/taste'], datum['review/appearance'], datum['review/aroma'], datum['review/palate'], datum['review/overall']]\n",
    "  return feat\n",
    "\n",
    "X = [feature(d) for d in data]\n",
    "y = [d['beer/ABV'] >= 6.5 for d in data]\n",
    "\n",
    "def inner(x,y):\n",
    "  return sum([x[i]*y[i] for i in range(len(x))])\n",
    "\n",
    "def sigmoid(x):\n",
    "  return 1.0 / (1 + exp(-x))\n",
    "\n",
    "##################################################\n",
    "# Logistic regression by gradient ascent         #\n",
    "##################################################\n",
    "\n",
    "# NEGATIVE Log-likelihood\n",
    "def f(theta, X, y, lam):\n",
    "  loglikelihood = 0\n",
    "  for i in range(len(X)):\n",
    "    logit = inner(X[i], theta)\n",
    "    loglikelihood -= log(1 + exp(-logit))\n",
    "    if not y[i]:\n",
    "      loglikelihood -= logit\n",
    "  for k in range(len(theta)):\n",
    "    loglikelihood -= lam * theta[k]*theta[k]\n",
    "  # for debugging\n",
    "  # print(\"ll =\" + str(loglikelihood))\n",
    "  return -loglikelihood\n",
    "\n",
    "# NEGATIVE Derivative of log-likelihood\n",
    "def fprime(theta, X, y, lam):\n",
    "  dl = [0]*len(theta)\n",
    "  for i in range(len(X)):\n",
    "    logit = inner(X[i], theta)\n",
    "    for k in range(len(theta)):\n",
    "      dl[k] += X[i][k] * (1 - sigmoid(logit))\n",
    "      if not y[i]:\n",
    "        dl[k] -= X[i][k]\n",
    "  for k in range(len(theta)):\n",
    "    dl[k] -= lam*2*theta[k]\n",
    "  return numpy.array([-x for x in dl])\n",
    "\n",
    "X_train = X\n",
    "y_train = y\n",
    "\n",
    "##################################################\n",
    "# Train                                          #\n",
    "##################################################\n",
    "\n",
    "def train(lam):\n",
    "  theta,_,_ = scipy.optimize.fmin_l_bfgs_b(f, [0]*len(X[0]), fprime, pgtol = 10, args = (X_train, y_train, lam))\n",
    "  return theta\n",
    "\n",
    "##################################################\n",
    "# Predict                                        #\n",
    "##################################################\n",
    "\n",
    "def performance(theta):\n",
    "    scores = [inner(theta,x) for x in X]\n",
    "    predictions = [s > 0 for s in scores]\n",
    "    correct = [(a==b) for (a,b) in zip(predictions,y_train)]\n",
    "    acc = sum(correct) * 1.0 / len(correct)\n",
    "    return acc\n",
    "\n",
    "##################################################\n",
    "# Validation pipeline                            #\n",
    "##################################################\n",
    "\n",
    "lam = 1.0\n",
    "\n",
    "theta = train(lam)\n",
    "acc = performance(theta)\n",
    "print(\"lambda = \" + str(lam) + \":\\taccuracy=\" + str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of sets: Train 16666, Test 16667, Validate 16667\n",
      "Training performance: 0.7158886355454218\n",
      "Test set performance: 0.7166256674866502\n",
      "Validation set performance: 0.7223855522889542\n"
     ]
    }
   ],
   "source": [
    "#Question 1\n",
    "dataCopy = data.copy()\n",
    "random.shuffle(dataCopy)\n",
    "data_train = dataCopy[:len(dataCopy)//3]\n",
    "data_test = dataCopy[len(dataCopy)//3:round(2*len(dataCopy)/3)]\n",
    "data_valid = dataCopy[round(2*len(dataCopy)/3):]\n",
    "\n",
    "print('Length of sets: Train {}, Test {}, Validate {}'.format(len(data_train), len(data_test), len(data_valid)))\n",
    "\n",
    "X_train = [feature(d) for d in data_train]\n",
    "y_train = [d['beer/ABV'] >= 6.5 for d in data_train]\n",
    "X_test = [feature(d) for d in data_test]\n",
    "y_test = [d['beer/ABV'] >= 6.5 for d in data_test]\n",
    "X_valid = [feature(d) for d in data_valid]\n",
    "y_valid = [d['beer/ABV'] >= 6.5 for d in data_valid]\n",
    "\n",
    "def performance(theta, featureM, labelM):\n",
    "    scores = [inner(theta,x) for x in featureM]\n",
    "    predictions = [s > 0 for s in scores]\n",
    "    correct = [(a==b) for (a,b) in zip(predictions,labelM)]\n",
    "    acc = sum(correct) * 1.0 / len(correct)\n",
    "    return acc\n",
    "\n",
    "theta = train(lam)\n",
    "print('Training performance: {}'.format(performance(theta, X_train, y_train)))\n",
    "print('Test set performance: {}'.format(performance(theta, X_test, y_test)))\n",
    "print('Validation set performance: {}'.format(performance(theta, X_valid, y_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 9023\n",
      "True Negatives: 2921\n",
      "Positives: 12468\n",
      "Negatives: 4199\n",
      "False Positives: 3445\n",
      "False Negatives: 1278\n"
     ]
    }
   ],
   "source": [
    "#Question 2\n",
    "def performance(theta, featureM, labelM, mode='P'):\n",
    "    scores = [inner(theta,x) for x in featureM]\n",
    "    predictions = [s > 0 for s in scores]\n",
    "    if (mode == 'TP'):\n",
    "        correct = sum([(a==b and a == 1) for (a,b) in zip(predictions,labelM)])\n",
    "    if (mode == 'TN'):\n",
    "        correct = sum([(a==b and a == 0) for (a,b) in zip(predictions,labelM)])\n",
    "    if (mode == 'P'):\n",
    "        correct = sum([(a == 1) for (a,b) in zip(predictions,labelM)])\n",
    "    if (mode == 'N'):\n",
    "        correct = sum([(a == 0) for (a,b) in zip(predictions,labelM)])\n",
    "    if (mode == 'FP'):\n",
    "        correct = sum([(a!=b and a == 1) for (a,b) in zip(predictions,labelM)])\n",
    "    if (mode == 'FN'):\n",
    "        correct = sum([(a!=b and a == 0) for (a,b) in zip(predictions,labelM)])\n",
    "    return correct\n",
    "TP = performance(theta, X_test, y_test, 'TP')\n",
    "TN = performance(theta, X_test, y_test, 'TN')\n",
    "P = performance(theta, X_test, y_test, 'P')\n",
    "N = performance(theta, X_test, y_test, 'N')\n",
    "FP = performance(theta, X_test, y_test, 'FP')\n",
    "FN = performance(theta, X_test, y_test, 'FN')\n",
    "print('True Positives: {}'.format(TP))\n",
    "print('True Negatives: {}'.format(TN))\n",
    "print('Positives: {}'.format(P))\n",
    "print('Negatives: {}'.format(N))\n",
    "print('False Positives: {}'.format(FP))\n",
    "print('False Negatives: {}'.format(FN))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7236926531921719\n",
      "Recall: 0.8759343753033686\n",
      "100\n",
      "Precision@100: 0.91\n",
      "Recall@100: 1.0\n"
     ]
    }
   ],
   "source": [
    "#Question 3\n",
    "print('Precision: {}'.format(TP/(TP+FP)))\n",
    "print('Recall: {}'.format(TP/(TP+FN)))\n",
    "\n",
    "def PRL(theta, featureM, labelM, limit):\n",
    "    print(limit)\n",
    "    scores = [inner(theta,x) for x in featureM]\n",
    "    sortedScores = sorted(zip(scores, labelM), key=lambda tup:tup[0],reverse=True)\n",
    "    sortedLabels = [i[1] for i in sortedScores]\n",
    "    sortedPreds = [i[0] > 0 for i in sortedScores]\n",
    "    TP = sum([(a==b and a == 1) for (a,b) in zip(sortedPreds[:limit],sortedLabels[:limit])])\n",
    "    FP = correct = sum([(a!=b and a == 1) for (a,b) in zip(sortedPreds[:limit],sortedLabels[:limit])])\n",
    "    FN = correct = sum([(a!=b and a == 0) for (a,b) in zip(sortedPreds[:limit],sortedLabels[:limit])])\n",
    "    if (TP != 0):\n",
    "        return (TP/(TP+FP), TP/(TP+FN))\n",
    "    else:\n",
    "        return(0,0)\n",
    "results = PRL(theta, X_test, y_test, 100)\n",
    "print('Precision@100: {}'.format(results[0]))\n",
    "print('Recall@100: {}'.format(results[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Question 4\n",
    "def PRL(theta, featureM, labelM):\n",
    "    scores = [inner(theta,x) for x in featureM]\n",
    "    sortedScores = sorted(zip(scores, labelM), key=lambda tup:tup[0],reverse=True)\n",
    "    sortedLabels = [i[1] for i in sortedScores]\n",
    "    sortedPreds = [i[0] > 0 for i in sortedScores]\n",
    "    return (sortedPreds, sortedLabels)\n",
    "\n",
    "(preds, labels) = PRL(theta, X_test, y_test)\n",
    "resultP = []\n",
    "resultR = []\n",
    "TP_all = [(a==b and a == 1) for (a,b) in zip(preds,labels)]\n",
    "FP_all = [(a!=b and a == 1) for (a,b) in zip(preds,labels)]\n",
    "FN_all = [(a!=b and a == 0) for (a,b) in zip(preds,labels)]\n",
    "TP = 0\n",
    "TP_sum = sum(TP_all)\n",
    "FP = 0\n",
    "FN = sum(FN_all)\n",
    "for limit in range(len(X_test)):\n",
    "    TP += TP_all[limit]\n",
    "    FP += FP_all[limit]\n",
    "#    FN += FN_all[limit]\n",
    "    if (TP != 0):\n",
    "        resultP.append(TP/(TP+FP))\n",
    "        resultR.append(TP/(TP_sum+FN))\n",
    "    else:\n",
    "        resultP.append(0)\n",
    "        resultR.append(0)\n",
    "plt.plot(resultR, resultP, 'ro')\n",
    "plt.axis([0, 1, 0, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the biggest connected component: 40\n"
     ]
    }
   ],
   "source": [
    "#Question 5\n",
    "inputF = open('egonet.txt', 'r')\n",
    "G = nx.Graph()\n",
    "nodes = []\n",
    "edges = []\n",
    "for line in inputF.readlines():\n",
    "    both = line.split(' ')\n",
    "    first = both[0]\n",
    "    second = both[1].split('\\n')[0]\n",
    "    nodes.append(first)\n",
    "    nodes.append(second)\n",
    "    edges.append((first,second))\n",
    "uniqueNodes = set(nodes)\n",
    "for node in uniqueNodes:\n",
    "    G.add_node(node)\n",
    "for edge in edges:\n",
    "    G.add_edge(*edge)\n",
    "CCs = list(nx.connected_components(G))\n",
    "\n",
    "maxVal = 0\n",
    "for CC in CCs:\n",
    "    if len(CC) > maxVal:\n",
    "        maxVal = len(CC)\n",
    "        maxCC = CC\n",
    "print('Size of the biggest connected component: {}'.format(maxVal))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized cut cost: 0.8448117539026632\n"
     ]
    }
   ],
   "source": [
    "#Question 6\n",
    "sortedCC = sorted(maxCC)\n",
    "minVals = sortedCC[:round(len(maxCC)/2)]\n",
    "maxVals = sortedCC[round(len(maxCC)/2):]\n",
    "print('Normalized cut cost: {}'.format(nx.normalized_cut_size(G,minVals,maxVals)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 7\n",
    "minCost = 1.1\n",
    "currentCost = 1.0\n",
    "stable1 = minVals.copy()\n",
    "stable2 = maxVals.copy()\n",
    "while (currentCost < minCost):\n",
    "    minCost = currentCost\n",
    "    minValIter = 1.0\n",
    "    minId = ''\n",
    "    for i in range(len(stable1)):\n",
    "        val = stable1[i]\n",
    "        testCut1 = stable1.copy()\n",
    "        testCut1.remove(val)\n",
    "        testCut2 = stable2.copy()\n",
    "        testCut2.append(val)\n",
    "        cost = nx.normalized_cut_size(G,testCut1,testCut2)\n",
    "        if (cost < minValIter):\n",
    "            minId = val\n",
    "            minValIter = cost\n",
    "        if (cost == minValIter and int(minId) > int(val) if minId != '' else True):\n",
    "            minId = val\n",
    "            minValIter = cost\n",
    "            \n",
    "    for i in range(len(stable2)):\n",
    "        val = stable2[i]\n",
    "        testCut1 = stable1.copy()\n",
    "        testCut1.append(val)\n",
    "        testCut2 = stable2.copy()\n",
    "        testCut2.remove(val)\n",
    "        cost = nx.normalized_cut_size(G,testCut1,testCut2)\n",
    "        if (cost < minValIter):\n",
    "            minId = val\n",
    "            minValIter = cost\n",
    "        if (cost == minValIter and int(minId) > int(val) if minId != '' else True):\n",
    "            minId = val\n",
    "            minValIter = cost\n",
    "    if minValIter < currentCost:\n",
    "        if (minId in stable1):\n",
    "            stable1.remove(minId)\n",
    "            stable2.append(minId)\n",
    "        else:\n",
    "            stable1.append(minId)\n",
    "            stable2.remove(minId)\n",
    "        currentCost = minValIter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First split elements: ['697', '703', '708', '713', '719', '745', '747', '753', '769', '772', '774', '798', '800', '803', '805', '810', '811', '819', '828', '823', '830', '840', '880', '890', '869', '856']\n",
      "Second split elements: ['825', '861', '863', '864', '876', '878', '882', '884', '886', '888', '889', '893', '729', '804']\n",
      "Minimum normalized cut cost this split achieves: 0.19634091923248548\n"
     ]
    }
   ],
   "source": [
    "print('First split elements: {}'.format(stable1))\n",
    "print('Second split elements: {}'.format(stable2))\n",
    "print('Minimum normalized cut cost this split achieves: {}'.format(nx.normalized_cut_size(G,stable1,stable2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.02111111111111111"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Question 8\n",
    "def modularity(G, communities, weight=None):\n",
    "    multigraph = G.is_multigraph()\n",
    "    m = G.size(weight=weight)\n",
    "    out_degree = dict(G.degree(weight=weight))\n",
    "    in_degree = out_degree\n",
    "    norm = 1 / (2 * m)\n",
    "    def val(u, v):\n",
    "        try:\n",
    "            if multigraph:\n",
    "                w = sum(d.get(weight, 1) for k, d in G[u][v].items())\n",
    "            else:\n",
    "                w = G[u][v].get(weight, 1)\n",
    "        except KeyError:\n",
    "            w = 0\n",
    "        if u == v:\n",
    "            w *= 2\n",
    "        return w - in_degree[u] * out_degree[v] * norm\n",
    "\n",
    "    Q = sum(val(u, v) for c in communities for u, v in product(c, repeat=2))\n",
    "    return Q * norm\n",
    "moduleList = [set([i]) for i in sortedCC]\n",
    "\n",
    "initialScore = modularity(G, moduleList)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
