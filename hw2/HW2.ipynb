{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from itertools import combinations\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "done\n",
      "lambda = 1.0:\taccuracy=0.71868\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from urllib.request import urlopen\n",
    "import scipy.optimize\n",
    "import random\n",
    "from math import exp\n",
    "from math import log\n",
    "\n",
    "def parseData(fname):\n",
    "  for l in urlopen(fname):\n",
    "    yield eval(l)\n",
    "\n",
    "print(\"Reading data...\")\n",
    "data = list(parseData(\"http://jmcauley.ucsd.edu/cse190/data/beer/beer_50000.json\"))\n",
    "print(\"done\")\n",
    "\n",
    "def feature(datum):\n",
    "  feat = [1, datum['review/taste'], datum['review/appearance'], datum['review/aroma'], datum['review/palate'], datum['review/overall']]\n",
    "  return feat\n",
    "\n",
    "X = [feature(d) for d in data]\n",
    "y = [d['beer/ABV'] >= 6.5 for d in data]\n",
    "\n",
    "def inner(x,y):\n",
    "  return sum([x[i]*y[i] for i in range(len(x))])\n",
    "\n",
    "def sigmoid(x):\n",
    "  return 1.0 / (1 + exp(-x))\n",
    "\n",
    "##################################################\n",
    "# Logistic regression by gradient ascent         #\n",
    "##################################################\n",
    "\n",
    "# NEGATIVE Log-likelihood\n",
    "def f(theta, X, y, lam):\n",
    "  loglikelihood = 0\n",
    "  for i in range(len(X)):\n",
    "    logit = inner(X[i], theta)\n",
    "    loglikelihood -= log(1 + exp(-logit))\n",
    "    if not y[i]:\n",
    "      loglikelihood -= logit\n",
    "  for k in range(len(theta)):\n",
    "    loglikelihood -= lam * theta[k]*theta[k]\n",
    "  # for debugging\n",
    "  # print(\"ll =\" + str(loglikelihood))\n",
    "  return -loglikelihood\n",
    "\n",
    "# NEGATIVE Derivative of log-likelihood\n",
    "def fprime(theta, X, y, lam):\n",
    "  dl = [0]*len(theta)\n",
    "  for i in range(len(X)):\n",
    "    logit = inner(X[i], theta)\n",
    "    for k in range(len(theta)):\n",
    "      dl[k] += X[i][k] * (1 - sigmoid(logit))\n",
    "      if not y[i]:\n",
    "        dl[k] -= X[i][k]\n",
    "  for k in range(len(theta)):\n",
    "    dl[k] -= lam*2*theta[k]\n",
    "  return numpy.array([-x for x in dl])\n",
    "\n",
    "X_train = X\n",
    "y_train = y\n",
    "\n",
    "##################################################\n",
    "# Train                                          #\n",
    "##################################################\n",
    "\n",
    "def train(lam):\n",
    "  theta,_,_ = scipy.optimize.fmin_l_bfgs_b(f, [0]*len(X[0]), fprime, pgtol = 10, args = (X_train, y_train, lam))\n",
    "  return theta\n",
    "\n",
    "##################################################\n",
    "# Predict                                        #\n",
    "##################################################\n",
    "\n",
    "def performance(theta):\n",
    "    scores = [inner(theta,x) for x in X]\n",
    "    predictions = [s > 0 for s in scores]\n",
    "    correct = [(a==b) for (a,b) in zip(predictions,y_train)]\n",
    "    acc = sum(correct) * 1.0 / len(correct)\n",
    "    return acc\n",
    "\n",
    "##################################################\n",
    "# Validation pipeline                            #\n",
    "##################################################\n",
    "\n",
    "lam = 1.0\n",
    "\n",
    "theta = train(lam)\n",
    "acc = performance(theta)\n",
    "print(\"lambda = \" + str(lam) + \":\\taccuracy=\" + str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of sets: Train 16666, Test 16667, Validate 16667\n",
      "Training performance: 0.7207488299531981\n",
      "Test set performance: 0.7188456230875383\n",
      "Validation set performance: 0.7177656446871062\n"
     ]
    }
   ],
   "source": [
    "#Question 1\n",
    "dataCopy = data.copy()\n",
    "random.shuffle(dataCopy)\n",
    "data_train = dataCopy[:len(dataCopy)//3]\n",
    "data_test = dataCopy[len(dataCopy)//3:round(2*len(dataCopy)/3)]\n",
    "data_valid = dataCopy[round(2*len(dataCopy)/3):]\n",
    "\n",
    "print('Length of sets: Train {}, Test {}, Validate {}'.format(len(data_train), len(data_test), len(data_valid)))\n",
    "\n",
    "X_train = [feature(d) for d in data_train]\n",
    "y_train = [d['beer/ABV'] >= 6.5 for d in data_train]\n",
    "X_test = [feature(d) for d in data_test]\n",
    "y_test = [d['beer/ABV'] >= 6.5 for d in data_test]\n",
    "X_valid = [feature(d) for d in data_valid]\n",
    "y_valid = [d['beer/ABV'] >= 6.5 for d in data_valid]\n",
    "\n",
    "def performance(theta, featureM, labelM):\n",
    "    scores = [inner(theta,x) for x in featureM]\n",
    "    predictions = [s > 0 for s in scores]\n",
    "    correct = [(a==b) for (a,b) in zip(predictions,labelM)]\n",
    "    acc = sum(correct) * 1.0 / len(correct)\n",
    "    return acc\n",
    "\n",
    "theta = train(lam)\n",
    "print('Training performance: {}'.format(performance(theta, X_train, y_train)))\n",
    "print('Test set performance: {}'.format(performance(theta, X_test, y_test)))\n",
    "print('Validation set performance: {}'.format(performance(theta, X_valid, y_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 8990\n",
      "True Negatives: 2991\n",
      "Positives: 12314\n",
      "Negatives: 4353\n",
      "False Positives: 3324\n",
      "False Negatives: 1362\n"
     ]
    }
   ],
   "source": [
    "#Question 2\n",
    "def performance(theta, featureM, labelM, mode='P'):\n",
    "    scores = [inner(theta,x) for x in featureM]\n",
    "    predictions = [s > 0 for s in scores]\n",
    "    if (mode == 'TP'):\n",
    "        correct = sum([(a==b and a == 1) for (a,b) in zip(predictions,labelM)])\n",
    "    if (mode == 'TN'):\n",
    "        correct = sum([(a==b and a == 0) for (a,b) in zip(predictions,labelM)])\n",
    "    if (mode == 'P'):\n",
    "        correct = sum([(a == 1) for (a,b) in zip(predictions,labelM)])\n",
    "    if (mode == 'N'):\n",
    "        correct = sum([(a == 0) for (a,b) in zip(predictions,labelM)])\n",
    "    if (mode == 'FP'):\n",
    "        correct = sum([(a!=b and a == 1) for (a,b) in zip(predictions,labelM)])\n",
    "    if (mode == 'FN'):\n",
    "        correct = sum([(a!=b and a == 0) for (a,b) in zip(predictions,labelM)])\n",
    "    return correct\n",
    "TP = performance(theta, X_test, y_test, 'TP')\n",
    "TN = performance(theta, X_test, y_test, 'TN')\n",
    "P = performance(theta, X_test, y_test, 'P')\n",
    "N = performance(theta, X_test, y_test, 'N')\n",
    "FP = performance(theta, X_test, y_test, 'FP')\n",
    "FN = performance(theta, X_test, y_test, 'FN')\n",
    "print('True Positives: {}'.format(TP))\n",
    "print('True Negatives: {}'.format(TN))\n",
    "print('Positives: {}'.format(P))\n",
    "print('Negatives: {}'.format(N))\n",
    "print('False Positives: {}'.format(FP))\n",
    "print('False Negatives: {}'.format(FN))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7300633425369498\n",
      "Recall: 0.8684312210200927\n",
      "Precision@100: 0.95\n",
      "Recall@100: 1.0\n"
     ]
    }
   ],
   "source": [
    "#Question 3\n",
    "print('Precision: {}'.format(TP/(TP+FP)))\n",
    "print('Recall: {}'.format(TP/(TP+FN)))\n",
    "\n",
    "def PRL(theta, featureM, labelM, limit):\n",
    "    scores = [inner(theta,x) for x in featureM]\n",
    "    sortedScores = sorted(zip(scores, labelM), key=lambda tup:tup[0],reverse=True)\n",
    "    sortedLabels = [i[1] for i in sortedScores]\n",
    "    sortedPreds = [i[0] > 0 for i in sortedScores]\n",
    "    TP = sum([(a==b and a == 1) for (a,b) in zip(sortedPreds[:limit],sortedLabels[:limit])])\n",
    "    FP = correct = sum([(a!=b and a == 1) for (a,b) in zip(sortedPreds[:limit],sortedLabels[:limit])])\n",
    "    FN = correct = sum([(a!=b and a == 0) for (a,b) in zip(sortedPreds[:limit],sortedLabels[:limit])])\n",
    "    if (TP != 0):\n",
    "        return (TP/(TP+FP), TP/(TP+FN))\n",
    "    else:\n",
    "        return(0,0)\n",
    "results = PRL(theta, X_test, y_test, 100)\n",
    "print('Precision@100: {}'.format(results[0]))\n",
    "print('Recall@100: {}'.format(results[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Question 4\n",
    "def PRL(theta, featureM, labelM):\n",
    "    scores = [inner(theta,x) for x in featureM]\n",
    "    sortedScores = sorted(zip(scores, labelM), key=lambda tup:tup[0],reverse=True)\n",
    "    sortedLabels = [i[1] for i in sortedScores]\n",
    "    sortedPreds = [i[0] > 0 for i in sortedScores]\n",
    "    return (sortedPreds, sortedLabels)\n",
    "\n",
    "(preds, labels) = PRL(theta, X_test, y_test)\n",
    "resultP = []\n",
    "resultR = []\n",
    "TP_all = [(a==b and a == 1) for (a,b) in zip(preds,labels)]\n",
    "FP_all = [(a!=b and a == 1) for (a,b) in zip(preds,labels)]\n",
    "FN_all = [(a!=b and a == 0) for (a,b) in zip(preds,labels)]\n",
    "TP = 0\n",
    "TP_sum = sum(TP_all)\n",
    "FP = 0\n",
    "FN = sum(FN_all)\n",
    "for limit in range(len(X_test)):\n",
    "    TP += TP_all[limit]\n",
    "    FP += FP_all[limit]\n",
    "#    FN += FN_all[limit]\n",
    "    if (TP != 0):\n",
    "        resultP.append(TP/(TP+FP))\n",
    "        resultR.append(TP/(TP_sum+FN))\n",
    "    else:\n",
    "        resultP.append(0)\n",
    "        resultR.append(0)\n",
    "plt.plot(resultR, resultP, 'ro')\n",
    "plt.axis([0, 1, 0, 1])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the biggest connected component: 40\n",
      "Connected component:{'878', '888', '886', '830', '708', '805', '774', '713', '840', '810', '747', '856', '869', '876', '772', '890', '719', '882', '804', '769', '745', '880', '753', '823', '863', '703', '800', '828', '893', '884', '889', '803', '729', '825', '819', '811', '798', '861', '697', '864'}\n"
     ]
    }
   ],
   "source": [
    "#Question 5\n",
    "inputF = open('egonet.txt', 'r')\n",
    "G = nx.Graph()\n",
    "nodes = []\n",
    "edges = []\n",
    "for line in inputF.readlines():\n",
    "    both = line.split(' ')\n",
    "    first = both[0]\n",
    "    second = both[1].split('\\n')[0]\n",
    "    nodes.append(first)\n",
    "    nodes.append(second)\n",
    "    edges.append((first,second))\n",
    "uniqueNodes = set(nodes)\n",
    "for node in uniqueNodes:\n",
    "    G.add_node(node)\n",
    "for edge in edges:\n",
    "    G.add_edge(*edge)\n",
    "CCs = list(nx.connected_components(G))\n",
    "\n",
    "maxVal = 0\n",
    "for CC in CCs:\n",
    "    if len(CC) > maxVal:\n",
    "        maxVal = len(CC)\n",
    "        maxCC = CC\n",
    "print('Size of the biggest connected component: {}'.format(maxVal))\n",
    "print('Connected component:{}'.format(maxCC))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized cut cost: 0.8448117539026632\n",
      "First part: ['697', '703', '708', '713', '719', '729', '745', '747', '753', '769', '772', '774', '798', '800', '803', '804', '805', '810', '811', '819']\n",
      "Second part: ['823', '825', '828', '830', '840', '856', '861', '863', '864', '869', '876', '878', '880', '882', '884', '886', '888', '889', '890', '893']\n"
     ]
    }
   ],
   "source": [
    "#Question 6\n",
    "sortedCC = sorted(maxCC)\n",
    "minVals = sortedCC[:round(len(maxCC)/2)]\n",
    "maxVals = sortedCC[round(len(maxCC)/2):]\n",
    "print('Normalized cut cost: {}'.format(nx.normalized_cut_size(G,minVals,maxVals)))\n",
    "print('First part: {}'.format(minVals))\n",
    "print('Second part: {}'.format(maxVals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First split elements: ['697', '703', '708', '713', '719', '745', '747', '753', '769', '772', '774', '798', '800', '803', '805', '810', '811', '819', '828', '823', '830', '840', '880', '890', '869', '856']\n",
      "Second split elements: ['825', '861', '863', '864', '876', '878', '882', '884', '886', '888', '889', '893', '729', '804']\n",
      "Minimum normalized cut cost this split achieves: 0.19634091923248548\n"
     ]
    }
   ],
   "source": [
    "#Question 7\n",
    "minCost = 1.1\n",
    "currentCost = 1.0\n",
    "stable1 = minVals.copy()\n",
    "stable2 = maxVals.copy()\n",
    "while (currentCost < minCost):\n",
    "    minCost = currentCost\n",
    "    minValIter = 1.0\n",
    "    minId = ''\n",
    "    for i in range(len(stable1)):\n",
    "        val = stable1[i]\n",
    "        testCut1 = stable1.copy()\n",
    "        testCut1.remove(val)\n",
    "        testCut2 = stable2.copy()\n",
    "        testCut2.append(val)\n",
    "        cost = nx.normalized_cut_size(G,testCut1,testCut2)\n",
    "        if (cost < minValIter):\n",
    "            minId = val\n",
    "            minValIter = cost\n",
    "        if (cost == minValIter and int(minId) > int(val) if minId != '' else True):\n",
    "            minId = val\n",
    "            minValIter = cost\n",
    "            \n",
    "    for i in range(len(stable2)):\n",
    "        val = stable2[i]\n",
    "        testCut1 = stable1.copy()\n",
    "        testCut1.append(val)\n",
    "        testCut2 = stable2.copy()\n",
    "        testCut2.remove(val)\n",
    "        cost = nx.normalized_cut_size(G,testCut1,testCut2)\n",
    "        if (cost < minValIter):\n",
    "            minId = val\n",
    "            minValIter = cost\n",
    "        if (cost == minValIter and int(minId) > int(val) if minId != '' else True):\n",
    "            minId = val\n",
    "            minValIter = cost\n",
    "    if minValIter < currentCost:\n",
    "        if (minId in stable1):\n",
    "            stable1.remove(minId)\n",
    "            stable2.append(minId)\n",
    "        else:\n",
    "            stable1.append(minId)\n",
    "            stable2.remove(minId)\n",
    "        currentCost = minValIter\n",
    "print('First split elements: {}'.format(stable1))\n",
    "print('Second split elements: {}'.format(stable2))\n",
    "print('Minimum normalized cut cost this split achieves: {}'.format(nx.normalized_cut_size(G,stable1,stable2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial communities: [{'697'}, {'703'}, {'708'}, {'713'}, {'719'}, {'729'}, {'745'}, {'747'}, {'753'}, {'769'}, {'772'}, {'774'}, {'798'}, {'800'}, {'803'}, {'804'}, {'805'}, {'810'}, {'811'}, {'819'}, {'823'}, {'825'}, {'828'}, {'830'}, {'840'}, {'856'}, {'861'}, {'863'}, {'864'}, {'869'}, {'876'}, {'878'}, {'880'}, {'882'}, {'884'}, {'886'}, {'888'}, {'889'}, {'890'}, {'893'}]\n",
      "Communities are enclosed by curly braces\n",
      "Maximum modularity achieved: 0.814537037037037\n",
      "Maximum modularity communities: [{'878', '888', '886', '830', '708', '805', '774', '713', '840', '810', '747', '856', '869', '876', '772', '890', '719', '882', '804', '769', '745', '880', '753', '823', '863', '703', '800', '828', '893', '884', '803', '889', '729', '798', '825', '819', '811', '861', '697', '864'}]\n"
     ]
    }
   ],
   "source": [
    "#Question 8\n",
    "def modularity(G, communities, weight=None):\n",
    "    def calculateE(c):\n",
    "        edgesOf = list(combinations(c,2))\n",
    "        num_edges = 0\n",
    "        for combo in edgesOf:\n",
    "            num_edges += G.number_of_edges(*combo)\n",
    "        return num_edges/G.number_of_edges()\n",
    "    def calculateA(c):\n",
    "        for node in c:\n",
    "            endpoints = G[node]\n",
    "            num_endpoints = len(endpoints)\n",
    "            if (node in endpoints):\n",
    "                num_endpoints += 1\n",
    "            return num_endpoints/(G.number_of_edges()*2)\n",
    "    Q = 0\n",
    "    for c in communities:\n",
    "        Q += (calculateE(c) - (calculateA(c)**2))\n",
    "    return Q\n",
    "moduleList = [set([i]) for i in sortedCC]\n",
    "currentScore = modularity(G, moduleList)\n",
    "maxScore = -math.inf\n",
    "print('Initial communities: {}'.format(moduleList))\n",
    "while (currentScore > maxScore):\n",
    "    maxScore = currentScore\n",
    "    currentIter = currentScore\n",
    "    for i in range(len(moduleList)):\n",
    "        for j in range(i+1,len(moduleList)):\n",
    "            temp = moduleList.copy()\n",
    "            join1 = moduleList[i]\n",
    "            join2 = moduleList[j]\n",
    "            joined = join1.union(join2)\n",
    "            temp.remove(join1)\n",
    "            temp.remove(join2)\n",
    "            temp.append(joined)\n",
    "            currentVal = modularity(G,temp)\n",
    "            if (currentVal > currentIter):\n",
    "                maxList = temp\n",
    "                currentIter = currentVal\n",
    "    if (currentIter > currentScore):\n",
    "        currentScore = currentIter\n",
    "        moduleList = temp\n",
    "print('Communities are enclosed by curly braces')\n",
    "print('Maximum modularity achieved: {}'.format(currentScore))\n",
    "print('Maximum modularity communities: {}'.format(moduleList))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
