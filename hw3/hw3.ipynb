{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "def readGz(f):\n",
    "    for l in gzip.open(f):\n",
    "        yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Rating baseline: compute averages for each user, or return the global average if we've never seen the user before\n",
    "\n",
    "allRatings = []\n",
    "userRatings = defaultdict(list)\n",
    "for l in readGz(\"train.json.gz\"):\n",
    "    user,business = l['reviewerID'],l['itemID']\n",
    "    allRatings.append(l['rating'])\n",
    "    userRatings[user].append(l['rating'])\n",
    "\n",
    "globalAverage = sum(allRatings) / len(allRatings)\n",
    "userAverage = {}\n",
    "for u in userRatings:\n",
    "    userAverage[u] = sum(userRatings[u]) / len(userRatings[u])\n",
    "\n",
    "predictions = open(\"predictions_Rating.txt\", 'w')\n",
    "for l in open(\"pairs_Rating.txt\"):\n",
    "    if l.startswith(\"reviewerID\"):\n",
    "    #header\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,i = l.strip().split('-')\n",
    "    if u in userAverage:\n",
    "        predictions.write(u + '-' + i + ',' + str(userAverage[u]) + '\\n')\n",
    "    else:\n",
    "        predictions.write(u + '-' + i + ',' + str(globalAverage) + '\\n')\n",
    "\n",
    "predictions.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Would-purchase baseline: just rank which businesses are popular and which are not, and return '1' if a business is among the top-ranked\n",
    "businessCount = defaultdict(int)\n",
    "totalPurchases = 0\n",
    "purchases = defaultdict(set)\n",
    "purchasesTest = defaultdict(set)\n",
    "items = set()\n",
    "count = 0\n",
    "allData = defaultdict(int)\n",
    "allPurchases = 0\n",
    "categoryTrain = defaultdict(set)\n",
    "itemCategories = defaultdict(str)\n",
    "for l in readGz(\"train.json.gz\"):\n",
    "    user,business = l['reviewerID'],l['itemID']\n",
    "    allData[business] += 1\n",
    "    allPurchases += 1\n",
    "    if count <= 100000:\n",
    "        businessCount[business] += 1\n",
    "        totalPurchases += 1\n",
    "        count += 1\n",
    "    else:\n",
    "        purchasesTest[l['reviewerID']].add(l['itemID'])\n",
    "    purchases[l['reviewerID']].add(l['itemID'])\n",
    "    categoryTrain[l['reviewerID']].add(l['categoryID'])\n",
    "    itemCategories[l['itemID']] = l['categoryID']\n",
    "    items.add(l['itemID'])\n",
    "\n",
    "#Non-purchase pairs\n",
    "negatives = defaultdict(set)\n",
    "itemsList = list(items)\n",
    "users = list(purchases.keys())\n",
    "count = 0\n",
    "while count < 100000:\n",
    "    cus = random.choice(users)\n",
    "    item = random.choice(itemsList)\n",
    "    if item not in purchases[cus] and item not in negatives[cus]:\n",
    "        negatives[cus].add(item)\n",
    "        count += 1\n",
    "mostPopular = [(businessCount[x], x) for x in businessCount]\n",
    "mostPopular.sort()\n",
    "mostPopular.reverse()\n",
    "\n",
    "mostPopAll = [(allData[x], x) for x in allData]\n",
    "mostPopAll.sort()\n",
    "mostPopAll.reverse()\n",
    "\n",
    "validation = []\n",
    "return1 = set()\n",
    "for u in negatives.keys():\n",
    "    for i in negatives[u]:\n",
    "        validation.append((u,i,0))\n",
    "for u in purchasesTest.keys():\n",
    "    for i in purchasesTest[u]:\n",
    "        validation.append((u,i,1))\n",
    "factor = 0.5\n",
    "count = 0\n",
    "for ic, i in mostPopular:\n",
    "        count += ic\n",
    "        return1.add(i)\n",
    "        if count > (totalPurchases*factor): break\n",
    "correct = 0\n",
    "for p in validation:\n",
    "    if (p[1] in return1):\n",
    "        if (p[2] == 1):\n",
    "            correct += 1\n",
    "    elif (p[2] == 0):\n",
    "        correct += 1\n",
    "print('Original model validation accuracy is: {}'.format(correct/len(validation)))\n",
    "popular = 1\n",
    "            \n",
    "factor = 0.48\n",
    "maxAcc = 0\n",
    "maxFactor = 0\n",
    "for k in range(1000):\n",
    "    factor += 0.0001\n",
    "    return1 = set()\n",
    "    count = 0\n",
    "    for ic, i in mostPopular:\n",
    "        count += ic\n",
    "        return1.add(i)\n",
    "        if count > (totalPurchases*factor): break\n",
    "    correct = 0\n",
    "    for p in validation:\n",
    "        if (p[1] in return1):\n",
    "            if (p[2] == 1):\n",
    "                correct += 1\n",
    "        elif (p[2] == 0):\n",
    "            correct += 1\n",
    "    if ((correct/len(validation)) > maxAcc):\n",
    "        maxAcc = (correct/len(validation))\n",
    "        maxFactor = factor\n",
    "print('Validation accuracy is: {} at factor {}'.format(maxAcc, maxFactor))\n",
    "\n",
    "\n",
    "popular = 1 #Choose which model to use. (Category model doesn't output accuracy as not required by the question)\n",
    "#Predicting with the popularity model\n",
    "if (popular == 1):\n",
    "    return1 = set()\n",
    "    count = 0\n",
    "    for ic, i in mostPopular:\n",
    "        count += ic\n",
    "        return1.add(i)\n",
    "        if count > (totalPurchases*maxFactor): break\n",
    "\n",
    "    predictions = open(\"predictions_Purchase.txt\", 'w')\n",
    "    for l in open(\"pairs_Purchase.txt\"):\n",
    "        if l.startswith(\"reviewerID\"):\n",
    "        #header\n",
    "            predictions.write(l)\n",
    "            continue\n",
    "        u,i = l.strip().split('-')\n",
    "        if i in return1:\n",
    "            predictions.write(u + '-' + i + \",1\\n\")\n",
    "        else:\n",
    "            predictions.write(u + '-' + i + \",0\\n\")\n",
    "    predictions.close()\n",
    "else:\n",
    "    #Predicting with the category model\n",
    "    predictions = open(\"predictions_Purchase.txt\", 'w')\n",
    "    for l in open(\"pairs_Purchase.txt\"):\n",
    "        if l.startswith(\"reviewerID\"):\n",
    "        #header\n",
    "            predictions.write(l)\n",
    "            continue\n",
    "        u,i = l.strip().split('-')\n",
    "        if itemCategories[i] in categoryTrain[u]:\n",
    "            predictions.write(u + '-' + i + \",1\\n\")\n",
    "        else:\n",
    "            predictions.write(u + '-' + i + \",0\\n\")\n",
    "    predictions.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "catDict = {\n",
    "  \"Women\": 0,\n",
    "  \"Men\": 1,\n",
    "  \"Girls\": 2,\n",
    "  \"Boys\": 3,\n",
    "  \"Baby\": 4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Category prediction baseline: Just consider some of the most common words from each category\n",
    "\n",
    "\n",
    "def createList():\n",
    "    return [0,0,0,0,0]\n",
    "\n",
    "categoryCountsTrain = defaultdict(int)\n",
    "userCategoryCountsTrain = defaultdict(createList)\n",
    "categoryCountsVal = defaultdict(int)\n",
    "userCategoryCountsVal = defaultdict(createList)\n",
    "count = 0\n",
    "for l in readGz(\"train.json.gz\"):\n",
    "    if count < 100000:\n",
    "        categoryCountsTrain[l['categoryID']] += 1\n",
    "        userCategoryCountsTrain[l['reviewerID']][l['categoryID']] += 1\n",
    "        count += 1\n",
    "    else:\n",
    "        categoryCountsVal[l['categoryID']] += 1\n",
    "        userCategoryCountsVal[l['reviewerID']][l['categoryID']] += 1\n",
    "    user,business = l['reviewerID'],l['itemID']\n",
    "    allRatings.append(l['rating'])\n",
    "    userRatings[user].append(l['rating'])\n",
    "\n",
    "favCategoriesTrain = defaultdict(int)\n",
    "favCategoriesVal = defaultdict(int)\n",
    "\n",
    "for cus in userCategoryCountsTrain:\n",
    "    userCategories = userCategoryCountsTrain[cus]\n",
    "    favCatVal = max(userCategories)\n",
    "    favCat = userCategories.index(favCatVal)\n",
    "    if (userCategories.count(favCatVal) > 1):\n",
    "        cats = []\n",
    "        for vals in userCategories:\n",
    "            if (vals == favCatVal):\n",
    "                cats.append(userCategories.index(vals))\n",
    "        for i in cats:\n",
    "            maxCat = 0\n",
    "            if (categoryCountsTrain[i] > categoryCountsTrain[maxCat]):\n",
    "                maxCat = i\n",
    "        favCat = maxCat\n",
    "    favCategoriesTrain[cus] = favCat\n",
    "    \n",
    "for cus in userCategoryCountsVal:\n",
    "    userCategories = userCategoryCountsVal[cus]\n",
    "    favCatVal = max(userCategories)\n",
    "    favCat = userCategories.index(favCatVal)\n",
    "    if (userCategories.count(favCatVal) > 1):\n",
    "        cats = []\n",
    "        for vals in userCategories:\n",
    "            if (vals == favCatVal):\n",
    "                cats.append(userCategories.index(vals))\n",
    "        for i in cats:\n",
    "            maxCat = 0\n",
    "            if (categoryCountsVal[i] > categoryCountsVal[maxCat]):\n",
    "                maxCat = i\n",
    "        favCat = maxCat\n",
    "    favCategoriesVal[cus] = favCat\n",
    "correct = 0\n",
    "total = 0\n",
    "for user in favCategoriesVal:\n",
    "    total += 1\n",
    "    if user in favCategoriesTrain.keys():\n",
    "        predicted = favCategoriesTrain[user]\n",
    "    else:\n",
    "        predicted = 0\n",
    "    real = favCategoriesVal[user]\n",
    "    if (predicted == real):\n",
    "        correct += 1\n",
    "print('Accuracy of category prediction on validation set: {}'.format(correct/total))\n",
    "    \n",
    "predictions = open(\"predictions_Category.txt\", 'w')\n",
    "predictions.write(\"reviewerID-reviewHash,category\\n\")\n",
    "for l in readGz(\"test_Category.json.gz\"):\n",
    "    cat = catDict['Women'] # If there's no evidence, just choose the most common category in the dataset\n",
    "    words = l['reviewText'].lower()\n",
    "    if 'wife' in words:\n",
    "        cat = catDict['Women']\n",
    "    if 'husband' in words:\n",
    "        cat = catDict['Men']\n",
    "    if 'daughter' in words:\n",
    "        cat = catDict['Girls']\n",
    "    if 'son' in words:\n",
    "        cat = catDict['Boys']\n",
    "    if 'baby' in words:\n",
    "        cat = catDict['Baby']\n",
    "    predictions.write(l['reviewerID'] + '-' + l['reviewHash'] + \",\" + str(cat) + \"\\n\")\n",
    "\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words that are more frequent in Women category: ['i', 'it', 'love', 'bra', 'wear', 'but', 'so', 'was', 'cute', 'size']\n",
      "Words that are more frequent in Baby category: ['for', 'they', 'these', 'are', 'her', 'cute', 'old', 'my', 'little', 'she']\n",
      "Words that are more frequent in Boys category: ['he', 'son', 'for', 'my', 'old', 'him', 'his', 'year', 'we', 'loves']\n",
      "Words that are more frequent in Men category: ['he', 'watch', 'the', 'for', 'of', 'good', 'husband', 'these', 'his', 'you']\n",
      "Words that are more frequent in Girls category: ['she', 'her', 'daughter', 'for', 'my', 'old', 'it', 'year', 'loves', 'we']\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "import string\n",
    "translator = str.maketrans('', '', string.punctuation)\n",
    "def createDict():\n",
    "    return defaultdict(int)\n",
    "wordCount = defaultdict(int)\n",
    "categoryWordCount = defaultdict(createDict)\n",
    "count = 0\n",
    "testSet = []\n",
    "trainSet = []\n",
    "for l in readGz(\"train.json.gz\"):\n",
    "    if count < 100000:\n",
    "        sentence = l['reviewText'].translate(translator).lower()\n",
    "        words = sentence.split()\n",
    "        if 'categoryID' in l.keys():\n",
    "            for word in words:\n",
    "                wordCount[word] += 1\n",
    "                categoryWordCount[l['categoryID']][word] += 1\n",
    "            count += 1\n",
    "            trainSet.append((l['reviewText'], l['categoryID']))\n",
    "    else:\n",
    "        if 'categoryID' in l.keys():\n",
    "            testSet.append((l['reviewText'], l['categoryID']))\n",
    "topWords = sorted(wordCount.items(), key=operator.itemgetter(1))\n",
    "topWords.reverse()\n",
    "topWords = topWords[:500]\n",
    "\n",
    "\n",
    "total = sum(pair[1] for pair in topWords)\n",
    "totalCounts = defaultdict(int)\n",
    "frequencies = dict()\n",
    "for pair in topWords:\n",
    "    frequencies[pair[0]] = pair[1]/total\n",
    "    totalCounts[pair[0]] = pair[1]\n",
    "categoryFrequencies = defaultdict(list)\n",
    "categoryTotals = defaultdict(int)\n",
    "for categories in categoryWordCount.keys():\n",
    "#     categoryWords = categoryWordCount[categories]\n",
    "#     topWords = sorted(categoryWords.items(), key=operator.itemgetter(1))\n",
    "#     topWords.reverse()\n",
    "#     topWords = topWords[:(500 if len(topWords) > 500 else len(topWords))]\n",
    "#     catTotal = sum(pair[1] for pair in topWords)\n",
    "#     categoryTotals[categories] = catTotal\n",
    "    topFreqInCat = defaultdict(float)\n",
    "    categoryTotal = 0\n",
    "    for word in topWords:\n",
    "        categoryTotal += categoryWordCount[categories][word[0]]\n",
    "    for word in topWords:\n",
    "        topFreqInCat[word[0]] = categoryWordCount[categories][word[0]]/categoryTotal\n",
    "    wordFrequencies = [(x,topFreqInCat[x] - frequencies[x]) for x in topFreqInCat.keys()]\n",
    "    wordFrequencies.sort(key=operator.itemgetter(1))\n",
    "    wordFrequencies.reverse()\n",
    "    categoryFrequencies[categories] = wordFrequencies\n",
    "for cat in categoryFrequencies.keys():\n",
    "    printThis = [(pair[0]) for pair in categoryFrequencies[cat][:10]]\n",
    "    print(\"Words that are more frequent in {} category: {}\".format(list(catDict)[cat],printThis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "checkForWords = [pair[0] for pair in topWords]\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "shuffle(trainSet)\n",
    "maxCount = 10000\n",
    "for i in range(maxCount):\n",
    "    datum = trainSet[i]\n",
    "    review = datum[0].translate(translator).lower()\n",
    "    words = review.split()\n",
    "    feature = []\n",
    "    for word in checkForWords:\n",
    "        if word in words:\n",
    "            feature.append(1)\n",
    "        else:\n",
    "            feature.append(0)\n",
    "    X_train.append(feature)\n",
    "    y_train.append(datum[1])\n",
    "for datum in testSet:\n",
    "    review = datum[0].translate(translator).lower()\n",
    "    words = review.split()\n",
    "    feature = []\n",
    "    for word in checkForWords:\n",
    "        if word in words:\n",
    "            feature.append(1)\n",
    "        else:\n",
    "            feature.append(0)\n",
    "    X_test.append(feature)\n",
    "    y_test.append(datum[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC  \n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import classification_report, precision_score\n",
    "from multiprocessing import Process, Queue\n",
    "C_performance = Queue()\n",
    "cats = [0,1,2,3,4]\n",
    "C = [0.01,0.1,1,10,100]\n",
    "maxPrecision = 0\n",
    "maxC = 0\n",
    "processes = []\n",
    "\n",
    "def trainSvm(category,reg,X_train,y_train,X_test,y_test,Q):\n",
    "    y_train_cat = [(1 if i==category else 0) for i in y_train]\n",
    "    y_test_cat = [(1 if i==category else 0) for i in y_test]\n",
    "    clf = SVC(kernel='linear', C=reg)\n",
    "    clf.fit(X_train, y_train_cat)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    precision = precision_score(y_test_cat,y_pred, average='micro')\n",
    "    Q.put((category,reg,precision))\n",
    "    return clf\n",
    "\n",
    "for cat in cats:\n",
    "    for c in C:\n",
    "        p = Process(target=trainSvm,args=(cat,c,X_train,y_train,X_test,y_test,C_performance))\n",
    "        p.start()\n",
    "        processes.append(p)\n",
    "for p in processes:\n",
    "    p.join()\n",
    "\n",
    "results = []\n",
    "while (not C_performance.empty()):\n",
    "    results.append(C_performance.get())\n",
    "    \n",
    "result_Cat = defaultdict(list)\n",
    "for result in results:\n",
    "    result_Cat[result[0]].append((result[1],result[2]))\n",
    "\n",
    "regularizers = dict()\n",
    "for cat in result_Cat.keys():\n",
    "    pairs = result_Cat[cat]\n",
    "    pairs.sort(key=operator.itemgetter(0))\n",
    "    pairs.reverse()\n",
    "    best = max(pairs,key=operator.itemgetter(1))\n",
    "    regularizers[cat] = best[0]\n",
    "    print('Best regularization in category {} is {} with accuracy: {}'.format(list(catDict)[cat],best[0],best[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
