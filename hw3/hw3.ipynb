{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nabic\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import random\n",
    "from sklearn.svm import SVC  \n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import classification_report, precision_score\n",
    "from multiprocessing import Process, Queue\n",
    "\n",
    "from surprise import Dataset\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import Reader\n",
    "from surprise import KNNWithMeans\n",
    "from surprise import SVD\n",
    "from surprise import SVDpp\n",
    "import pandas as pd\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "def readGz(f):\n",
    "    for l in gzip.open(f):\n",
    "        yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Would-purchase baseline: just rank which businesses are popular and which are not, and return '1' if a business is among the top-ranked\n",
    "#Question 1,2,3,4\n",
    "businessCount = defaultdict(int)\n",
    "totalPurchases = 0\n",
    "purchases = defaultdict(set)\n",
    "purchasesTest = defaultdict(set)\n",
    "items = set()\n",
    "count = 0\n",
    "allData = defaultdict(int)\n",
    "allPurchases = 0\n",
    "categoryTrain = defaultdict(set)\n",
    "itemCategories = defaultdict(str)\n",
    "for l in readGz(\"train.json.gz\"):\n",
    "    user,business = l['reviewerID'],l['itemID']\n",
    "    allData[business] += 1\n",
    "    allPurchases += 1\n",
    "    if count <= 100000:\n",
    "        businessCount[business] += 1\n",
    "        totalPurchases += 1\n",
    "        count += 1\n",
    "    else:\n",
    "        purchasesTest[l['reviewerID']].add(l['itemID'])\n",
    "    purchases[l['reviewerID']].add(l['itemID'])\n",
    "    categoryTrain[l['reviewerID']].add(l['categoryID'])\n",
    "    itemCategories[l['itemID']] = l['categoryID']\n",
    "    items.add(l['itemID'])\n",
    "\n",
    "#Non-purchase pairs\n",
    "negatives = defaultdict(set)\n",
    "itemsList = list(items)\n",
    "users = list(purchases.keys())\n",
    "count = 0\n",
    "while count < 100000:\n",
    "    cus = random.choice(users)\n",
    "    item = random.choice(itemsList)\n",
    "    if item not in purchases[cus] and item not in negatives[cus]:\n",
    "        negatives[cus].add(item)\n",
    "        count += 1\n",
    "mostPopular = [(businessCount[x], x) for x in businessCount]\n",
    "mostPopular.sort()\n",
    "mostPopular.reverse()\n",
    "\n",
    "mostPopAll = [(allData[x], x) for x in allData]\n",
    "mostPopAll.sort()\n",
    "mostPopAll.reverse()\n",
    "\n",
    "validation = []\n",
    "return1 = set()\n",
    "for u in negatives.keys():\n",
    "    for i in negatives[u]:\n",
    "        validation.append((u,i,0))\n",
    "for u in purchasesTest.keys():\n",
    "    for i in purchasesTest[u]:\n",
    "        validation.append((u,i,1))\n",
    "factor = 0.5\n",
    "count = 0\n",
    "for ic, i in mostPopular:\n",
    "        count += ic\n",
    "        return1.add(i)\n",
    "        if count > (totalPurchases*factor): break\n",
    "correct = 0\n",
    "for p in validation:\n",
    "    if (p[1] in return1):\n",
    "        if (p[2] == 1):\n",
    "            correct += 1\n",
    "    elif (p[2] == 0):\n",
    "        correct += 1\n",
    "print('Original model validation accuracy is: {}'.format(correct/len(validation)))\n",
    "popular = 1\n",
    "            \n",
    "factor = 0.48\n",
    "maxAcc = 0\n",
    "maxFactor = 0\n",
    "for k in range(1000):\n",
    "    factor += 0.0001\n",
    "    return1 = set()\n",
    "    count = 0\n",
    "    for ic, i in mostPopular:\n",
    "        count += ic\n",
    "        return1.add(i)\n",
    "        if count > (totalPurchases*factor): break\n",
    "    correct = 0\n",
    "    for p in validation:\n",
    "        if (p[1] in return1):\n",
    "            if (p[2] == 1):\n",
    "                correct += 1\n",
    "        elif (p[2] == 0):\n",
    "            correct += 1\n",
    "    if ((correct/len(validation)) > maxAcc):\n",
    "        maxAcc = (correct/len(validation))\n",
    "        maxFactor = factor\n",
    "print('Validation accuracy is: {} at factor {}'.format(maxAcc, maxFactor))\n",
    "\n",
    "\n",
    "popular = 0 #Choose which model to use. (Category model doesn't output accuracy as not required by the question)\n",
    "#Predicting with the popularity model\n",
    "if (popular == 1):\n",
    "    return1 = set()\n",
    "    count = 0\n",
    "    for ic, i in mostPopular:\n",
    "        count += ic\n",
    "        return1.add(i)\n",
    "        if count > (totalPurchases*maxFactor): break\n",
    "\n",
    "    predictions = open(\"predictions_Purchase.txt\", 'w')\n",
    "    for l in open(\"pairs_Purchase.txt\"):\n",
    "        if l.startswith(\"reviewerID\"):\n",
    "        #header\n",
    "            predictions.write(l)\n",
    "            continue\n",
    "        u,i = l.strip().split('-')\n",
    "        if i in return1:\n",
    "            predictions.write(u + '-' + i + \",1\\n\")\n",
    "        else:\n",
    "            predictions.write(u + '-' + i + \",0\\n\")\n",
    "    predictions.close()\n",
    "else:\n",
    "    #Predicting with the category model\n",
    "    predictions = open(\"predictions_Purchase.txt\", 'w')\n",
    "    for l in open(\"pairs_Purchase.txt\"):\n",
    "        if l.startswith(\"reviewerID\"):\n",
    "        #header\n",
    "            predictions.write(l)\n",
    "            continue\n",
    "        u,i = l.strip().split('-')\n",
    "        if itemCategories[i] in categoryTrain[u]:\n",
    "            predictions.write(u + '-' + i + \",1\\n\")\n",
    "        else:\n",
    "            predictions.write(u + '-' + i + \",0\\n\")\n",
    "    predictions.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alt solution for purchase prediction\n",
    "userID = []\n",
    "itemID = []\n",
    "categoryID = []\n",
    "ratingAll = []\n",
    "purchased = []\n",
    "for l in readGz(\"train.json.gz\"):\n",
    "    user,business,category,rating = l['reviewerID'],l['itemID'], l['categoryID'], l['rating']\n",
    "    userID.append(user)\n",
    "    itemID.append(business)\n",
    "    categoryID.append(category)\n",
    "    ratingAll.append(rating)\n",
    "    purchased.append(1)\n",
    "# for user in negatives:\n",
    "#     for item in negatives[user]:\n",
    "#         userID.append(user)\n",
    "#         itemID.append(item)\n",
    "#         purchased.append(0)\n",
    "#         ratingAll.append(0.0)\n",
    "allDataDict = {'reviewerID':userID,\n",
    "              'itemID':itemID,\n",
    "              'purchase':purchased}\n",
    "df = pd.DataFrame(allDataDict)\n",
    "reader = Reader(rating_scale=(0,1))\n",
    "data = Dataset.load_from_df(df[['reviewerID','itemID','purchase']],reader)\n",
    "trainset, testset = train_test_split(data, test_size=.15,random_state=7)\n",
    "# algo = SVDpp(n_factors=140, n_epochs=100, lr_all=0.003, reg_all=0.15,verbose=True)\n",
    "algo = KNNWithMeans(k=100,verbose=True,sim_options={'name':'pearson'})\n",
    "algo.fit(trainset)\n",
    "test_pred = algo.test(testset)\n",
    "accuracy.rmse(test_pred,verbose=True)\n",
    "# param_grid = {'n_factors': [110, 120, 140], 'n_epochs': [100], 'lr_all': [0.003, 0.005],\n",
    "#               'reg_all': [0.08, 0.1, 0.15]}\n",
    "# gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=3)\n",
    "# gs.fit(data)\n",
    "# algo = gs.best_estimator['rmse']\n",
    "# print(gs.best_score['rmse'])\n",
    "# print(gs.best_params['rmse'])\n",
    "# cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_pred[25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userPred = []\n",
    "itemPred = []\n",
    "purchase = []\n",
    "predictData = []\n",
    "count = 0\n",
    "average = 0\n",
    "for i in ratingAll:\n",
    "    average += i\n",
    "average /= len(ratingAll)\n",
    "print(average)\n",
    "predictionsFile = open(\"predictions_Purchase.txt\", 'w')\n",
    "for l in open(\"pairs_Purchase.txt\"):\n",
    "    if l.startswith(\"reviewerID\"):\n",
    "        predictionsFile.write(l)\n",
    "        continue\n",
    "    u,i = l.strip().split('-')\n",
    "    userPred.append(u)\n",
    "    itemPred.append(i)\n",
    "    purchase.append(0)\n",
    "    predictData.append((u,i,0))\n",
    "predDict = {'userID':userPred,\n",
    "            'itemID':itemPred,\n",
    "            'purchase':purchase}\n",
    "predictDF = pd.DataFrame(predDict)\n",
    "# predictData = Dataset.load_from_df(predictDF[['userID','itemID','purchase']],reader)\n",
    "test_pred = algo.test(predictData)\n",
    "print(len(predictData))\n",
    "\n",
    "for pred in test_pred:\n",
    "    u = pred[0]\n",
    "    i = pred[1]\n",
    "    if pred[3] >= 0.5:\n",
    "         predictionsFile.write(u + '-' + i + \",1\\n\")\n",
    "    else:\n",
    "         predictionsFile.write(u + '-' + i + \",0\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_pred[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "catDict = {\n",
    "  \"Women\": 0,\n",
    "  \"Men\": 1,\n",
    "  \"Girls\": 2,\n",
    "  \"Boys\": 3,\n",
    "  \"Baby\": 4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Category prediction baseline: Just consider some of the most common words from each category\n",
    "#Question 5\n",
    "def createList():\n",
    "    return [0,0,0,0,0]\n",
    "\n",
    "categoryCountsTrain = defaultdict(int)\n",
    "userCategoryCountsTrain = defaultdict(createList)\n",
    "categoryCountsVal = defaultdict(int)\n",
    "userCategoryCountsVal = defaultdict(createList)\n",
    "count = 0\n",
    "allRatings = []\n",
    "userRatings = defaultdict(list)\n",
    "for l in readGz(\"train.json.gz\"):\n",
    "    if count < 100000:\n",
    "        categoryCountsTrain[l['categoryID']] += 1\n",
    "        userCategoryCountsTrain[l['reviewerID']][l['categoryID']] += 1\n",
    "        count += 1\n",
    "    else:\n",
    "        categoryCountsVal[l['categoryID']] += 1\n",
    "        userCategoryCountsVal[l['reviewerID']][l['categoryID']] += 1\n",
    "    user,business = l['reviewerID'],l['itemID']\n",
    "    allRatings.append(l['rating'])\n",
    "    userRatings[user].append(l['rating'])\n",
    "\n",
    "favCategoriesTrain = defaultdict(int)\n",
    "favCategoriesVal = defaultdict(int)\n",
    "\n",
    "for cus in userCategoryCountsTrain:\n",
    "    userCategories = userCategoryCountsTrain[cus]\n",
    "    favCatVal = max(userCategories)\n",
    "    favCat = userCategories.index(favCatVal)\n",
    "    if (userCategories.count(favCatVal) > 1):\n",
    "        cats = []\n",
    "        for vals in userCategories:\n",
    "            if (vals == favCatVal):\n",
    "                cats.append(userCategories.index(vals))\n",
    "        for i in cats:\n",
    "            maxCat = 0\n",
    "            if (categoryCountsTrain[i] > categoryCountsTrain[maxCat]):\n",
    "                maxCat = i\n",
    "        favCat = maxCat\n",
    "    favCategoriesTrain[cus] = favCat\n",
    "    \n",
    "for cus in userCategoryCountsVal:\n",
    "    userCategories = userCategoryCountsVal[cus]\n",
    "    favCatVal = max(userCategories)\n",
    "    favCat = userCategories.index(favCatVal)\n",
    "    if (userCategories.count(favCatVal) > 1):\n",
    "        cats = []\n",
    "        for vals in userCategories:\n",
    "            if (vals == favCatVal):\n",
    "                cats.append(userCategories.index(vals))\n",
    "        for i in cats:\n",
    "            maxCat = 0\n",
    "            if (categoryCountsVal[i] > categoryCountsVal[maxCat]):\n",
    "                maxCat = i\n",
    "        favCat = maxCat\n",
    "    favCategoriesVal[cus] = favCat\n",
    "correct = 0\n",
    "total = 0\n",
    "for user in favCategoriesVal:\n",
    "    total += 1\n",
    "    if user in favCategoriesTrain.keys():\n",
    "        predicted = favCategoriesTrain[user]\n",
    "    else:\n",
    "        predicted = 0\n",
    "    real = favCategoriesVal[user]\n",
    "    if (predicted == real):\n",
    "        correct += 1\n",
    "print('Accuracy of category prediction on validation set: {}'.format(correct/total))\n",
    "    \n",
    "predictions = open(\"predictions_Category.txt\", 'w')\n",
    "predictions.write(\"reviewerID-reviewHash,category\\n\")\n",
    "for l in readGz(\"test_Category.json.gz\"):\n",
    "    cat = catDict['Women'] # If there's no evidence, just choose the most common category in the dataset\n",
    "    words = l['reviewText'].lower()\n",
    "    if 'wife' in words:\n",
    "        cat = catDict['Women']\n",
    "    if 'husband' in words:\n",
    "        cat = catDict['Men']\n",
    "    if 'daughter' in words:\n",
    "        cat = catDict['Girls']\n",
    "    if 'son' in words:\n",
    "        cat = catDict['Boys']\n",
    "    if 'baby' in words:\n",
    "        cat = catDict['Baby']\n",
    "    predictions.write(l['reviewerID'] + '-' + l['reviewHash'] + \",\" + str(cat) + \"\\n\")\n",
    "\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words that are more frequent in Women category: ['i', 'it', 'love', 'bra', 'wear', 'but', 'so', 'was', 'cute', 'size']\n",
      "Words that are more frequent in Baby category: ['for', 'they', 'these', 'are', 'her', 'cute', 'old', 'my', 'little', 'she']\n",
      "Words that are more frequent in Boys category: ['he', 'son', 'for', 'my', 'old', 'him', 'his', 'year', 'we', 'loves']\n",
      "Words that are more frequent in Men category: ['he', 'watch', 'the', 'for', 'of', 'good', 'husband', 'these', 'his', 'you']\n",
      "Words that are more frequent in Girls category: ['she', 'her', 'daughter', 'for', 'my', 'old', 'it', 'year', 'loves', 'we']\n"
     ]
    }
   ],
   "source": [
    "#Question 6\n",
    "import operator\n",
    "import string\n",
    "translator = str.maketrans('', '', string.punctuation)\n",
    "def createDict():\n",
    "    return defaultdict(int)\n",
    "wordCount = defaultdict(int)\n",
    "categoryWordCount = defaultdict(createDict)\n",
    "count = 0\n",
    "testSet = []\n",
    "trainSet = []\n",
    "for l in readGz(\"train.json.gz\"):\n",
    "    if count < 100000:\n",
    "        sentence = l['reviewText'].translate(translator).lower()\n",
    "        words = sentence.split()\n",
    "        if 'categoryID' in l.keys():\n",
    "            for word in words:\n",
    "                wordCount[word] += 1\n",
    "                categoryWordCount[l['categoryID']][word] += 1\n",
    "            count += 1\n",
    "            trainSet.append((l['reviewText'], l['categoryID']))\n",
    "    else:\n",
    "        if 'categoryID' in l.keys():\n",
    "            testSet.append((l['reviewText'], l['categoryID']))\n",
    "topWords = sorted(wordCount.items(), key=operator.itemgetter(1))\n",
    "topWords.reverse()\n",
    "topWords = topWords[:500]\n",
    "\n",
    "\n",
    "total = sum(pair[1] for pair in topWords)\n",
    "totalCounts = defaultdict(int)\n",
    "frequencies = dict()\n",
    "for pair in topWords:\n",
    "    frequencies[pair[0]] = pair[1]/total\n",
    "    totalCounts[pair[0]] = pair[1]\n",
    "categoryFrequencies = defaultdict(list)\n",
    "categoryTotals = defaultdict(int)\n",
    "for categories in categoryWordCount.keys():\n",
    "#     categoryWords = categoryWordCount[categories]\n",
    "#     topWords = sorted(categoryWords.items(), key=operator.itemgetter(1))\n",
    "#     topWords.reverse()\n",
    "#     topWords = topWords[:(500 if len(topWords) > 500 else len(topWords))]\n",
    "#     catTotal = sum(pair[1] for pair in topWords)\n",
    "#     categoryTotals[categories] = catTotal\n",
    "    topFreqInCat = defaultdict(float)\n",
    "    categoryTotal = 0\n",
    "    for word in topWords:\n",
    "        categoryTotal += categoryWordCount[categories][word[0]]\n",
    "    for word in topWords:\n",
    "        topFreqInCat[word[0]] = categoryWordCount[categories][word[0]]/categoryTotal\n",
    "    wordFrequencies = [(x,topFreqInCat[x] - frequencies[x]) for x in topFreqInCat.keys()]\n",
    "    wordFrequencies.sort(key=operator.itemgetter(1))\n",
    "    wordFrequencies.reverse()\n",
    "    categoryFrequencies[categories] = wordFrequencies\n",
    "for cat in categoryFrequencies.keys():\n",
    "    printThis = [(pair[0]) for pair in categoryFrequencies[cat][:10]]\n",
    "    print(\"Words that are more frequent in {} category: {}\".format(list(catDict)[cat],printThis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 7,8\n",
    "from random import shuffle\n",
    "checkForWords = [pair[0] for pair in topWords]\n",
    "trainingSets = []\n",
    "testSets = []\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "shuffle(trainSet)\n",
    "maxCount = 10000\n",
    "for cat in range(5):\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for i in range(maxCount):\n",
    "        datum = trainSet[i]\n",
    "        review = datum[0].translate(translator).lower()\n",
    "        words = review.split()\n",
    "        feature = []\n",
    "        for (word,freq) in categoryFrequencies[cat]:\n",
    "            if word in words:\n",
    "                feature.append(1)\n",
    "            else:\n",
    "                feature.append(0)\n",
    "        X_train.append(feature)\n",
    "        y_train.append(datum[1])\n",
    "    trainingSets.append(X_train)\n",
    "for cat in range(5):\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    for datum in testSet:\n",
    "        review = datum[0].translate(translator).lower()\n",
    "        words = review.split()\n",
    "        feature = []\n",
    "        for (word,freq) in categoryFrequencies[cat]:\n",
    "            if word in words:\n",
    "                feature.append(1)\n",
    "            else:\n",
    "                feature.append(0)\n",
    "        X_test.append(feature)\n",
    "        y_test.append(datum[1])\n",
    "    testSets.append(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 7,8\n",
    "def trainSvm(category,reg,X_train,y_train,X_test,y_test,Q=Queue(),ker='rbf'):\n",
    "    y_train_cat = [(1 if i==category else 0) for i in y_train]\n",
    "    y_test_cat = [(1 if i==category else 0) for i in y_test]\n",
    "    clf = SVC(kernel=ker, C=reg)\n",
    "    clf.fit(X_train, y_train_cat)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    precision = precision_score(y_test_cat,y_pred, average='weighted')\n",
    "    print(precision,category)\n",
    "    #cm = confusion_matrix(y_test_cat,y_pred)\n",
    "    #print(cm)\n",
    "    Q.put((category,reg,precision))\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-415fed0d3bcc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mProcess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainSvm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrainingSets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtestSets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mC_performance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mprocesses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mprocesses\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\process.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    110\u001b[0m                \u001b[1;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    221\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpopen_spawn_win32\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 322\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m     \u001b[1;32mclass\u001b[0m \u001b[0mSpawnContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\popen_spawn_win32.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m                 \u001b[0mset_spawning_popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\reduction.py\u001b[0m in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;34m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[0mForkingPickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
     ]
    }
   ],
   "source": [
    "#Question 7,8\n",
    "C_performance = Queue()\n",
    "cats = [0,1]\n",
    "C = [0.01,0.1,1,10,100]\n",
    "kernels = ['linear','rbf']\n",
    "maxPrecision = 0\n",
    "maxC = 0\n",
    "processes = []\n",
    "\n",
    "for cat in cats:\n",
    "    for c in C:\n",
    "        p = Process(target=trainSvm,args=(cat,c,trainingSets[cat],y_train,testSets[cat],y_test,C_performance, kernels[0]))\n",
    "        p.start()\n",
    "        processes.append(p)\n",
    "for p in processes:\n",
    "    p.join()\n",
    "\n",
    "results = []\n",
    "while (not C_performance.empty()):\n",
    "    results.append(C_performance.get())\n",
    "    \n",
    "result_Cat = defaultdict(list)\n",
    "for result in results:\n",
    "    result_Cat[result[0]].append((result[1],result[2]))\n",
    "\n",
    "regularizers = dict()\n",
    "for cat in result_Cat.keys():\n",
    "    pairs = result_Cat[cat]\n",
    "    pairs.sort(key=operator.itemgetter(0))\n",
    "    pairs.reverse()\n",
    "    best = max(pairs,key=operator.itemgetter(1))\n",
    "    regularizers[cat] = best[0]\n",
    "    print('Best regularization in category {} is {} with accuracy: {}'.format(list(catDict)[cat],best[0],best[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nabic\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49730704000000003 0\n",
      "0.5490217216 1\n",
      "0.9771124801 2\n",
      "0.9809713936 3\n",
      "0.9708357961 4\n"
     ]
    }
   ],
   "source": [
    "#Question 7,8\n",
    "#Best values obtained from the tests above\n",
    "C_cat0 = 0.1 #Women\n",
    "C_cat1 = 0.1 #Men\n",
    "C_cat2 = 0.1 #Girls\n",
    "C_cat3 = 0.1 #Boys\n",
    "C_cat4 = 0.1 #Baby\n",
    "\n",
    "clf_cat0 = trainSvm(0,C_cat0,trainingSets[0],y_train,testSets[0],y_test)\n",
    "clf_cat1 = trainSvm(1,C_cat1,trainingSets[1],y_train,testSets[1],y_test)\n",
    "clf_cat2 = trainSvm(2,C_cat2,trainingSets[2],y_train,testSets[2],y_test)\n",
    "clf_cat3 = trainSvm(3,C_cat3,trainingSets[3],y_train,testSets[3],y_test)\n",
    "clf_cat4 = trainSvm(4,C_cat4,trainingSets[4],y_train,testSets[4],y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(len(trainingSets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting\n",
      "14000\n",
      "14000\n"
     ]
    }
   ],
   "source": [
    "#Question 7,8\n",
    "#print('Precision of classifier in Women category with regularizer {}: {}'.format(C_cat0, precision_score(y_test,clf_cat0.predict(X_test),average='micro')))\n",
    "      \n",
    "def predictCombined(X,size):\n",
    "    f0 = clf_cat0.decision_function(X[0][:size])\n",
    "    f1 = clf_cat1.decision_function(X[1][:size])\n",
    "    f2 = clf_cat2.decision_function(X[2][:size])\n",
    "    f3 = clf_cat3.decision_function(X[3][:size])\n",
    "    f4 = clf_cat4.decision_function(X[4][:size])\n",
    "\n",
    "    confidence = []\n",
    "    for i in range(len(X[0][:size])):\n",
    "        confidence.append((f0[i],f1[i],f2[i],f3[i],f4[i]))\n",
    "    y_pred = []\n",
    "    print(len(confidence))\n",
    "    for i in range(len(confidence)):\n",
    "        y_pred.append(confidence[i].index(max(confidence[i])))\n",
    "    print(len(y_pred))\n",
    "    return y_pred\n",
    "#testSize = 1000\n",
    "#print('Precision of the combined classifier: {}'.format(precision_score(y_test[:testSize],predictCombined(testSets,testSize), average='micro')))\n",
    "\n",
    "\n",
    "allFeatures = []\n",
    "predictions = open(\"predictions_Category.txt\", 'w')\n",
    "predictions.write(\"reviewerID-reviewHash,category\\n\")\n",
    "for cat in range(5):\n",
    "    finalLabels = []\n",
    "    finalFeatures = []\n",
    "    for l in readGz(\"test_Category.json.gz\"):\n",
    "        words = l['reviewText'].translate(translator)\n",
    "        words.lower()\n",
    "        feature = []\n",
    "        for (word,freq) in categoryFrequencies[cat]:\n",
    "            if word in words:\n",
    "                feature.append(1)\n",
    "            else:\n",
    "                feature.append(0)\n",
    "        finalFeatures.append(feature)\n",
    "        finalLabels.append((l['reviewerID'],l['reviewHash']))\n",
    "    allFeatures.append(finalFeatures)\n",
    "print('Predicting')\n",
    "pred = predictCombined(allFeatures, len(allFeatures[0]))\n",
    "i = 0\n",
    "for (revID,revHash) in finalLabels:\n",
    "    predictions.write(revID + '-' + revHash + \",\" + str(pred[i]) + \"\\n\")\n",
    "    i += 1\n",
    "\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(len(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
