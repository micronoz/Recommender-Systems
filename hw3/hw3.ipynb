{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import random\n",
    "from sklearn.svm import SVC  \n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import classification_report, precision_score\n",
    "from multiprocessing import Process, Queue\n",
    "\n",
    "from surprise import Dataset\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import Reader\n",
    "from surprise import KNNWithMeans\n",
    "import pandas as pd\n",
    "\n",
    "def readGz(f):\n",
    "    for l in gzip.open(f):\n",
    "        yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original model validation accuracy is: 0.628478142390712\n",
      "Validation accuracy is: 0.6291681458407292 at factor 0.5151999999999961\n"
     ]
    }
   ],
   "source": [
    "### Would-purchase baseline: just rank which businesses are popular and which are not, and return '1' if a business is among the top-ranked\n",
    "#Question 1,2,3,4\n",
    "businessCount = defaultdict(int)\n",
    "totalPurchases = 0\n",
    "purchases = defaultdict(set)\n",
    "purchasesTest = defaultdict(set)\n",
    "items = set()\n",
    "count = 0\n",
    "allData = defaultdict(int)\n",
    "allPurchases = 0\n",
    "categoryTrain = defaultdict(set)\n",
    "itemCategories = defaultdict(str)\n",
    "for l in readGz(\"train.json.gz\"):\n",
    "    user,business = l['reviewerID'],l['itemID']\n",
    "    allData[business] += 1\n",
    "    allPurchases += 1\n",
    "    if count <= 100000:\n",
    "        businessCount[business] += 1\n",
    "        totalPurchases += 1\n",
    "        count += 1\n",
    "    else:\n",
    "        purchasesTest[l['reviewerID']].add(l['itemID'])\n",
    "    purchases[l['reviewerID']].add(l['itemID'])\n",
    "    categoryTrain[l['reviewerID']].add(l['categoryID'])\n",
    "    itemCategories[l['itemID']] = l['categoryID']\n",
    "    items.add(l['itemID'])\n",
    "\n",
    "#Non-purchase pairs\n",
    "negatives = defaultdict(set)\n",
    "itemsList = list(items)\n",
    "users = list(purchases.keys())\n",
    "count = 0\n",
    "while count < 100000:\n",
    "    cus = random.choice(users)\n",
    "    item = random.choice(itemsList)\n",
    "    if item not in purchases[cus] and item not in negatives[cus]:\n",
    "        negatives[cus].add(item)\n",
    "        count += 1\n",
    "mostPopular = [(businessCount[x], x) for x in businessCount]\n",
    "mostPopular.sort()\n",
    "mostPopular.reverse()\n",
    "\n",
    "mostPopAll = [(allData[x], x) for x in allData]\n",
    "mostPopAll.sort()\n",
    "mostPopAll.reverse()\n",
    "\n",
    "validation = []\n",
    "return1 = set()\n",
    "for u in negatives.keys():\n",
    "    for i in negatives[u]:\n",
    "        validation.append((u,i,0))\n",
    "for u in purchasesTest.keys():\n",
    "    for i in purchasesTest[u]:\n",
    "        validation.append((u,i,1))\n",
    "factor = 0.5\n",
    "count = 0\n",
    "for ic, i in mostPopular:\n",
    "        count += ic\n",
    "        return1.add(i)\n",
    "        if count > (totalPurchases*factor): break\n",
    "correct = 0\n",
    "for p in validation:\n",
    "    if (p[1] in return1):\n",
    "        if (p[2] == 1):\n",
    "            correct += 1\n",
    "    elif (p[2] == 0):\n",
    "        correct += 1\n",
    "print('Original model validation accuracy is: {}'.format(correct/len(validation)))\n",
    "popular = 1\n",
    "            \n",
    "factor = 0.48\n",
    "maxAcc = 0\n",
    "maxFactor = 0\n",
    "for k in range(1000):\n",
    "    factor += 0.0001\n",
    "    return1 = set()\n",
    "    count = 0\n",
    "    for ic, i in mostPopular:\n",
    "        count += ic\n",
    "        return1.add(i)\n",
    "        if count > (totalPurchases*factor): break\n",
    "    correct = 0\n",
    "    for p in validation:\n",
    "        if (p[1] in return1):\n",
    "            if (p[2] == 1):\n",
    "                correct += 1\n",
    "        elif (p[2] == 0):\n",
    "            correct += 1\n",
    "    if ((correct/len(validation)) > maxAcc):\n",
    "        maxAcc = (correct/len(validation))\n",
    "        maxFactor = factor\n",
    "print('Validation accuracy is: {} at factor {}'.format(maxAcc, maxFactor))\n",
    "\n",
    "\n",
    "popular = 1 #Choose which model to use. (Category model doesn't output accuracy as not required by the question)\n",
    "#Predicting with the popularity model\n",
    "if (popular == 1):\n",
    "    return1 = set()\n",
    "    count = 0\n",
    "    for ic, i in mostPopular:\n",
    "        count += ic\n",
    "        return1.add(i)\n",
    "        if count > (totalPurchases*maxFactor): break\n",
    "\n",
    "    predictions = open(\"predictions_Purchase.txt\", 'w')\n",
    "    for l in open(\"pairs_Purchase.txt\"):\n",
    "        if l.startswith(\"reviewerID\"):\n",
    "        #header\n",
    "            predictions.write(l)\n",
    "            continue\n",
    "        u,i = l.strip().split('-')\n",
    "        if i in return1:\n",
    "            predictions.write(u + '-' + i + \",1\\n\")\n",
    "        else:\n",
    "            predictions.write(u + '-' + i + \",0\\n\")\n",
    "    predictions.close()\n",
    "else:\n",
    "    #Predicting with the category model\n",
    "    predictions = open(\"predictions_Purchase.txt\", 'w')\n",
    "    for l in open(\"pairs_Purchase.txt\"):\n",
    "        if l.startswith(\"reviewerID\"):\n",
    "        #header\n",
    "            predictions.write(l)\n",
    "            continue\n",
    "        u,i = l.strip().split('-')\n",
    "        if itemCategories[i] in categoryTrain[u]:\n",
    "            predictions.write(u + '-' + i + \",1\\n\")\n",
    "        else:\n",
    "            predictions.write(u + '-' + i + \",0\\n\")\n",
    "    predictions.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n"
     ]
    }
   ],
   "source": [
    "#Alt solution for purchase prediction\n",
    "userID = []\n",
    "itemID = []\n",
    "categoryID = []\n",
    "ratingAll = []\n",
    "purchased = []\n",
    "for l in readGz(\"train.json.gz\"):\n",
    "    user,business,category,rating = l['reviewerID'],l['itemID'], l['categoryID'], l['rating']\n",
    "    userID.append(user)\n",
    "    itemID.append(business)\n",
    "    categoryID.append(category)\n",
    "    ratingAll.append(rating)\n",
    "    purchased.append(1.0)\n",
    "for user in negatives:\n",
    "    for item in negatives[user]:\n",
    "        userID.append(user)\n",
    "        itemID.append(item)\n",
    "        purchased.append(0.0)\n",
    "allDataDict = {'reviewerID':userID,\n",
    "              'itemID':itemID,\n",
    "              'purchase':purchased}\n",
    "df = pd.DataFrame(allDataDict)\n",
    "reader = Reader(rating_scale=(0,1))\n",
    "data = Dataset.load_from_df(df[['reviewerID','itemID','purchase']],reader)\n",
    "trainset, testset = train_test_split(data, test_size=.15)\n",
    "algo = KNNWithMeans(k=50, sim_options={'name':'pearson_baseline','user_based':True})\n",
    "algo.fit(trainset)\n",
    "test_pred = algo.test(testset)\n",
    "accuracy.rmse(test_pred,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: U490934656 item: I402344648 r_ui = 4.00   est = 4.00   {'actual_k': 1, 'was_impossible': False}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "catDict = {\n",
    "  \"Women\": 0,\n",
    "  \"Men\": 1,\n",
    "  \"Girls\": 2,\n",
    "  \"Boys\": 3,\n",
    "  \"Baby\": 4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of category prediction on validation set: 0.8457227624855778\n"
     ]
    }
   ],
   "source": [
    "### Category prediction baseline: Just consider some of the most common words from each category\n",
    "#Question 5\n",
    "def createList():\n",
    "    return [0,0,0,0,0]\n",
    "\n",
    "categoryCountsTrain = defaultdict(int)\n",
    "userCategoryCountsTrain = defaultdict(createList)\n",
    "categoryCountsVal = defaultdict(int)\n",
    "userCategoryCountsVal = defaultdict(createList)\n",
    "count = 0\n",
    "allRatings = []\n",
    "userRatings = defaultdict(list)\n",
    "for l in readGz(\"train.json.gz\"):\n",
    "    if count < 100000:\n",
    "        categoryCountsTrain[l['categoryID']] += 1\n",
    "        userCategoryCountsTrain[l['reviewerID']][l['categoryID']] += 1\n",
    "        count += 1\n",
    "    else:\n",
    "        categoryCountsVal[l['categoryID']] += 1\n",
    "        userCategoryCountsVal[l['reviewerID']][l['categoryID']] += 1\n",
    "    user,business = l['reviewerID'],l['itemID']\n",
    "    allRatings.append(l['rating'])\n",
    "    userRatings[user].append(l['rating'])\n",
    "\n",
    "favCategoriesTrain = defaultdict(int)\n",
    "favCategoriesVal = defaultdict(int)\n",
    "\n",
    "for cus in userCategoryCountsTrain:\n",
    "    userCategories = userCategoryCountsTrain[cus]\n",
    "    favCatVal = max(userCategories)\n",
    "    favCat = userCategories.index(favCatVal)\n",
    "    if (userCategories.count(favCatVal) > 1):\n",
    "        cats = []\n",
    "        for vals in userCategories:\n",
    "            if (vals == favCatVal):\n",
    "                cats.append(userCategories.index(vals))\n",
    "        for i in cats:\n",
    "            maxCat = 0\n",
    "            if (categoryCountsTrain[i] > categoryCountsTrain[maxCat]):\n",
    "                maxCat = i\n",
    "        favCat = maxCat\n",
    "    favCategoriesTrain[cus] = favCat\n",
    "    \n",
    "for cus in userCategoryCountsVal:\n",
    "    userCategories = userCategoryCountsVal[cus]\n",
    "    favCatVal = max(userCategories)\n",
    "    favCat = userCategories.index(favCatVal)\n",
    "    if (userCategories.count(favCatVal) > 1):\n",
    "        cats = []\n",
    "        for vals in userCategories:\n",
    "            if (vals == favCatVal):\n",
    "                cats.append(userCategories.index(vals))\n",
    "        for i in cats:\n",
    "            maxCat = 0\n",
    "            if (categoryCountsVal[i] > categoryCountsVal[maxCat]):\n",
    "                maxCat = i\n",
    "        favCat = maxCat\n",
    "    favCategoriesVal[cus] = favCat\n",
    "correct = 0\n",
    "total = 0\n",
    "for user in favCategoriesVal:\n",
    "    total += 1\n",
    "    if user in favCategoriesTrain.keys():\n",
    "        predicted = favCategoriesTrain[user]\n",
    "    else:\n",
    "        predicted = 0\n",
    "    real = favCategoriesVal[user]\n",
    "    if (predicted == real):\n",
    "        correct += 1\n",
    "print('Accuracy of category prediction on validation set: {}'.format(correct/total))\n",
    "    \n",
    "predictions = open(\"predictions_Category.txt\", 'w')\n",
    "predictions.write(\"reviewerID-reviewHash,category\\n\")\n",
    "for l in readGz(\"test_Category.json.gz\"):\n",
    "    cat = catDict['Women'] # If there's no evidence, just choose the most common category in the dataset\n",
    "    words = l['reviewText'].lower()\n",
    "    if 'wife' in words:\n",
    "        cat = catDict['Women']\n",
    "    if 'husband' in words:\n",
    "        cat = catDict['Men']\n",
    "    if 'daughter' in words:\n",
    "        cat = catDict['Girls']\n",
    "    if 'son' in words:\n",
    "        cat = catDict['Boys']\n",
    "    if 'baby' in words:\n",
    "        cat = catDict['Baby']\n",
    "    predictions.write(l['reviewerID'] + '-' + l['reviewHash'] + \",\" + str(cat) + \"\\n\")\n",
    "\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 6\n",
    "import operator\n",
    "import string\n",
    "translator = str.maketrans('', '', string.punctuation)\n",
    "def createDict():\n",
    "    return defaultdict(int)\n",
    "wordCount = defaultdict(int)\n",
    "categoryWordCount = defaultdict(createDict)\n",
    "count = 0\n",
    "testSet = []\n",
    "trainSet = []\n",
    "for l in readGz(\"train.json.gz\"):\n",
    "    if count < 100000:\n",
    "        sentence = l['reviewText'].translate(translator).lower()\n",
    "        words = sentence.split()\n",
    "        if 'categoryID' in l.keys():\n",
    "            for word in words:\n",
    "                wordCount[word] += 1\n",
    "                categoryWordCount[l['categoryID']][word] += 1\n",
    "            count += 1\n",
    "            trainSet.append((l['reviewText'], l['categoryID']))\n",
    "    else:\n",
    "        if 'categoryID' in l.keys():\n",
    "            testSet.append((l['reviewText'], l['categoryID']))\n",
    "topWords = sorted(wordCount.items(), key=operator.itemgetter(1))\n",
    "topWords.reverse()\n",
    "topWords = topWords[:500]\n",
    "\n",
    "\n",
    "total = sum(pair[1] for pair in topWords)\n",
    "totalCounts = defaultdict(int)\n",
    "frequencies = dict()\n",
    "for pair in topWords:\n",
    "    frequencies[pair[0]] = pair[1]/total\n",
    "    totalCounts[pair[0]] = pair[1]\n",
    "categoryFrequencies = defaultdict(list)\n",
    "categoryTotals = defaultdict(int)\n",
    "for categories in categoryWordCount.keys():\n",
    "#     categoryWords = categoryWordCount[categories]\n",
    "#     topWords = sorted(categoryWords.items(), key=operator.itemgetter(1))\n",
    "#     topWords.reverse()\n",
    "#     topWords = topWords[:(500 if len(topWords) > 500 else len(topWords))]\n",
    "#     catTotal = sum(pair[1] for pair in topWords)\n",
    "#     categoryTotals[categories] = catTotal\n",
    "    topFreqInCat = defaultdict(float)\n",
    "    categoryTotal = 0\n",
    "    for word in topWords:\n",
    "        categoryTotal += categoryWordCount[categories][word[0]]\n",
    "    for word in topWords:\n",
    "        topFreqInCat[word[0]] = categoryWordCount[categories][word[0]]/categoryTotal\n",
    "    wordFrequencies = [(x,topFreqInCat[x] - frequencies[x]) for x in topFreqInCat.keys()]\n",
    "    wordFrequencies.sort(key=operator.itemgetter(1))\n",
    "    wordFrequencies.reverse()\n",
    "    categoryFrequencies[categories] = wordFrequencies\n",
    "for cat in categoryFrequencies.keys():\n",
    "    printThis = [(pair[0]) for pair in categoryFrequencies[cat]]\n",
    "    print(\"Words that are more frequent in {} category: {}\".format(list(catDict)[cat],printThis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 7,8\n",
    "from random import shuffle\n",
    "checkForWords = [pair[0] for pair in topWords]\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "shuffle(trainSet)\n",
    "maxCount = 10000\n",
    "for i in range(maxCount):\n",
    "    datum = trainSet[i]\n",
    "    review = datum[0].translate(translator).lower()\n",
    "    words = review.split()\n",
    "    feature = []\n",
    "    for word in checkForWords:\n",
    "        if word in words:\n",
    "            feature.append(1)\n",
    "        else:\n",
    "            feature.append(0)\n",
    "    X_train.append(feature)\n",
    "    y_train.append(datum[1])\n",
    "for datum in testSet:\n",
    "    review = datum[0].translate(translator).lower()\n",
    "    words = review.split()\n",
    "    feature = []\n",
    "    for word in checkForWords:\n",
    "        if word in words:\n",
    "            feature.append(1)\n",
    "        else:\n",
    "            feature.append(0)\n",
    "    X_test.append(feature)\n",
    "    y_test.append(datum[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "#Question 7,8\n",
    "\n",
    "def trainSvm(category,reg,X_train,y_train,X_test,y_test,Q=Queue()):\n",
    "    y_train_cat = [(1 if i==category else 0) for i in y_train]\n",
    "    y_test_cat = [(1 if i==category else 0) for i in y_test]\n",
    "    clf = SVC(kernel='linear', C=reg)\n",
    "    clf.fit(X_train, y_train_cat)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    precision = precision_score(y_test_cat,y_pred, average='micro')\n",
    "    Q.put((category,reg,precision))\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best regularization in category Boys is 0.1 with accuracy: 0.99045\n",
      "Best regularization in category Baby is 0.1 with accuracy: 0.98543\n",
      "Best regularization in category Girls is 0.1 with accuracy: 0.98849\n",
      "Best regularization in category Men is 0.1 with accuracy: 0.79523\n",
      "Best regularization in category Women is 0.1 with accuracy: 0.78057\n"
     ]
    }
   ],
   "source": [
    "#Question 7,8\n",
    "C_performance = Queue()\n",
    "cats = [0,1,2,3,4]\n",
    "C = [0.01,0.1,1,10,100]\n",
    "maxPrecision = 0\n",
    "maxC = 0\n",
    "processes = []\n",
    "\n",
    "for cat in cats:\n",
    "    for c in C:\n",
    "        p = Process(target=trainSvm,args=(cat,c,X_train,y_train,X_test,y_test,C_performance))\n",
    "        p.start()\n",
    "        processes.append(p)\n",
    "for p in processes:\n",
    "    p.join()\n",
    "\n",
    "results = []\n",
    "while (not C_performance.empty()):\n",
    "    results.append(C_performance.get())\n",
    "    \n",
    "result_Cat = defaultdict(list)\n",
    "for result in results:\n",
    "    result_Cat[result[0]].append((result[1],result[2]))\n",
    "\n",
    "regularizers = dict()\n",
    "for cat in result_Cat.keys():\n",
    "    pairs = result_Cat[cat]\n",
    "    pairs.sort(key=operator.itemgetter(0))\n",
    "    pairs.reverse()\n",
    "    best = max(pairs,key=operator.itemgetter(1))\n",
    "    regularizers[cat] = best[0]\n",
    "    print('Best regularization in category {} is {} with accuracy: {}'.format(list(catDict)[cat],best[0],best[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 7,8\n",
    "#Best values obtained from the tests above\n",
    "C_cat0 = 0.1 #Women\n",
    "C_cat1 = 0.1 #Men\n",
    "C_cat2 = 0.1 #Girls\n",
    "C_cat3 = 0.1 #Boys\n",
    "C_cat4 = 0.1 #Baby\n",
    "\n",
    "clf_cat0 = trainSvm(0,C_cat0,X_train,y_train,X_test,y_test)\n",
    "clf_cat1 = trainSvm(1,C_cat1,X_train,y_train,X_test,y_test)\n",
    "clf_cat2 = trainSvm(2,C_cat2,X_train,y_train,X_test,y_test)\n",
    "clf_cat3 = trainSvm(3,C_cat3,X_train,y_train,X_test,y_test)\n",
    "clf_cat4 = trainSvm(4,C_cat4,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of classifier in Women category with regularizer 0.1: 0.19616\n",
      "Precision of the combined classifier: 0.771\n"
     ]
    }
   ],
   "source": [
    "#Question 7,8\n",
    "print('Precision of classifier in Women category with regularizer {}: {}'.format(C_cat0, precision_score(y_test,clf_cat0.predict(X_test),average='micro')))\n",
    "      \n",
    "def predictCombined(X, size):\n",
    "    f0 = clf_cat0.decision_function(X[:size])\n",
    "    f1 = clf_cat1.decision_function(X[:size])\n",
    "    f2 = clf_cat2.decision_function(X[:size])\n",
    "    f3 = clf_cat3.decision_function(X[:size])\n",
    "    f4 = clf_cat4.decision_function(X[:size])\n",
    "\n",
    "    confidence = []\n",
    "    for i in range(len(X[:size])):\n",
    "        confidence.append((f0[i],f1[i],f2[i],f3[i],f4[i]))\n",
    "    y_pred = []\n",
    "    for i in range(len(confidence)):\n",
    "        y_pred.append(confidence[i].index(max(confidence[i])))\n",
    "    return y_pred\n",
    "testSize = 1000\n",
    "print('Precision of the combined classifier: {}'.format(precision_score(y_test[:testSize],predictCombined(X_test,testSize), average='micro')))\n",
    "\n",
    "finalFeatures = []\n",
    "finalLabels = []\n",
    "predictions = open(\"predictions_Category.txt\", 'w')\n",
    "predictions.write(\"reviewerID-reviewHash,category\\n\")\n",
    "for l in readGz(\"test_Category.json.gz\"):\n",
    "    words = l['reviewText'].translate(translator)\n",
    "    words.lower()\n",
    "    feature = []\n",
    "    for word in checkForWords:\n",
    "        if word in words:\n",
    "            feature.append(1)\n",
    "        else:\n",
    "            feature.append(0)\n",
    "    finalFeatures.append(feature)\n",
    "    finalLabels.append((l['reviewerID'],l['reviewHash']))\n",
    "    \n",
    "pred = predictCombined(finalFeatures, len(finalFeatures))\n",
    "i = 0\n",
    "for (revID,revHash) in finalLabels:\n",
    "    predictions.write(revID + '-' + revHash + \",\" + str(pred[i]) + \"\\n\")\n",
    "    i += 1\n",
    "\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
