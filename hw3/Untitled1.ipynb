{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nabic\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import random\n",
    "from sklearn.svm import SVC  \n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import classification_report, precision_score\n",
    "from multiprocessing import Process, Queue\n",
    "\n",
    "from surprise import Dataset\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import Reader\n",
    "from surprise import KNNWithMeans\n",
    "from surprise import SVD\n",
    "from surprise import SVDpp\n",
    "import pandas as pd\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "def readGz(f):\n",
    "    for l in gzip.open(f):\n",
    "        yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " processing epoch 0\n",
      " processing epoch 1\n",
      " processing epoch 2\n",
      " processing epoch 3\n",
      " processing epoch 4\n",
      " processing epoch 5\n",
      " processing epoch 6\n",
      " processing epoch 7\n",
      " processing epoch 8\n",
      " processing epoch 9\n",
      " processing epoch 10\n",
      " processing epoch 11\n",
      " processing epoch 12\n",
      " processing epoch 13\n",
      " processing epoch 14\n",
      " processing epoch 15\n",
      " processing epoch 16\n",
      " processing epoch 17\n",
      " processing epoch 18\n",
      " processing epoch 19\n",
      " processing epoch 20\n",
      " processing epoch 21\n",
      " processing epoch 22\n",
      " processing epoch 23\n",
      " processing epoch 24\n",
      " processing epoch 25\n",
      " processing epoch 26\n",
      " processing epoch 27\n",
      " processing epoch 28\n",
      " processing epoch 29\n",
      " processing epoch 30\n",
      " processing epoch 31\n",
      " processing epoch 32\n",
      " processing epoch 33\n",
      " processing epoch 34\n",
      " processing epoch 35\n",
      " processing epoch 36\n",
      " processing epoch 37\n",
      " processing epoch 38\n",
      " processing epoch 39\n",
      " processing epoch 40\n",
      " processing epoch 41\n",
      " processing epoch 42\n",
      " processing epoch 43\n",
      " processing epoch 44\n",
      " processing epoch 45\n",
      " processing epoch 46\n",
      " processing epoch 47\n",
      " processing epoch 48\n",
      " processing epoch 49\n",
      " processing epoch 50\n",
      " processing epoch 51\n",
      " processing epoch 52\n",
      " processing epoch 53\n",
      " processing epoch 54\n",
      " processing epoch 55\n",
      " processing epoch 56\n",
      " processing epoch 57\n",
      " processing epoch 58\n",
      " processing epoch 59\n",
      " processing epoch 60\n",
      " processing epoch 61\n",
      " processing epoch 62\n",
      " processing epoch 63\n",
      " processing epoch 64\n",
      " processing epoch 65\n",
      " processing epoch 66\n",
      " processing epoch 67\n",
      " processing epoch 68\n",
      " processing epoch 69\n",
      " processing epoch 70\n",
      " processing epoch 71\n",
      " processing epoch 72\n",
      " processing epoch 73\n",
      " processing epoch 74\n",
      " processing epoch 75\n",
      " processing epoch 76\n",
      " processing epoch 77\n",
      " processing epoch 78\n",
      " processing epoch 79\n",
      " processing epoch 80\n",
      " processing epoch 81\n",
      " processing epoch 82\n",
      " processing epoch 83\n",
      " processing epoch 84\n",
      " processing epoch 85\n",
      " processing epoch 86\n",
      " processing epoch 87\n",
      " processing epoch 88\n",
      " processing epoch 89\n",
      " processing epoch 90\n",
      " processing epoch 91\n",
      " processing epoch 92\n",
      " processing epoch 93\n",
      " processing epoch 94\n",
      " processing epoch 95\n",
      " processing epoch 96\n",
      " processing epoch 97\n",
      " processing epoch 98\n",
      " processing epoch 99\n",
      "RMSE: 0.0467\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.04668493451623727"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Alt solution for purchase prediction\n",
    "userID = []\n",
    "itemID = []\n",
    "categoryID = []\n",
    "ratingAll = []\n",
    "purchased = []\n",
    "for l in readGz(\"train.json.gz\"):\n",
    "    user,business,category,rating = l['reviewerID'],l['itemID'], l['categoryID'], l['rating']\n",
    "    userID.append(user)\n",
    "    itemID.append(business)\n",
    "    categoryID.append(category)\n",
    "    ratingAll.append(rating)\n",
    "    purchased.append(1)\n",
    "# for user in negatives:\n",
    "#     for item in negatives[user]:\n",
    "#         userID.append(user)\n",
    "#         itemID.append(item)\n",
    "#         purchased.append(0)\n",
    "#         ratingAll.append(0.0)\n",
    "allDataDict = {'reviewerID':userID,\n",
    "              'itemID':itemID,\n",
    "              'purchase':purchased}\n",
    "df = pd.DataFrame(allDataDict)\n",
    "reader = Reader(rating_scale=(0,1))\n",
    "data = Dataset.load_from_df(df[['reviewerID','itemID','purchase']],reader)\n",
    "trainset, testset = train_test_split(data, test_size=.15,random_state=7)\n",
    "algo = SVDpp(n_factors=140, n_epochs=100, lr_all=0.003, reg_all=0.15,verbose=True)\n",
    "# algo = KNNWithMeans(verbose=True,sim_options={'name':'cosine', 'user_based':False})\n",
    "algo.fit(trainset)\n",
    "test_pred = algo.test(testset)\n",
    "accuracy.rmse(test_pred,verbose=True)\n",
    "# param_grid = {'n_factors': [110, 120, 140], 'n_epochs': [100], 'lr_all': [0.003, 0.005],\n",
    "#               'reg_all': [0.08, 0.1, 0.15]}\n",
    "# gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=3)\n",
    "# gs.fit(data)\n",
    "# algo = gs.best_estimator['rmse']\n",
    "# print(gs.best_score['rmse'])\n",
    "# print(gs.best_params['rmse'])\n",
    "# cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.23471\n",
      "28000\n"
     ]
    }
   ],
   "source": [
    "userPred = []\n",
    "itemPred = []\n",
    "purchase = []\n",
    "predictData = []\n",
    "count = 0\n",
    "average = 0\n",
    "for i in ratingAll:\n",
    "    average += i\n",
    "average /= len(ratingAll)\n",
    "print(average)\n",
    "predictionsFile = open(\"predictions_Purchase.txt\", 'w')\n",
    "for l in open(\"pairs_Purchase.txt\"):\n",
    "    if l.startswith(\"reviewerID\"):\n",
    "        predictionsFile.write(l)\n",
    "        continue\n",
    "    u,i = l.strip().split('-')\n",
    "    userPred.append(u)\n",
    "    itemPred.append(i)\n",
    "    purchase.append(0)\n",
    "    predictData.append((u,i,0))\n",
    "predDict = {'userID':userPred,\n",
    "            'itemID':itemPred,\n",
    "            'purchase':purchase}\n",
    "predictDF = pd.DataFrame(predDict)\n",
    "# predictData = Dataset.load_from_df(predictDF[['userID','itemID','purchase']],reader)\n",
    "test_pred = algo.test(predictData)\n",
    "print(len(predictData))\n",
    "\n",
    "for pred in test_pred:\n",
    "    u = pred[0]\n",
    "    i = pred[1]\n",
    "    if pred[3] >= 0.5:\n",
    "         predictionsFile.write(u + '-' + i + \",1\\n\")\n",
    "    else:\n",
    "         predictionsFile.write(u + '-' + i + \",0\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
