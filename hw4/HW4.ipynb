{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import urllib\n",
    "import scipy.optimize\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import nltk\n",
    "import string\n",
    "from nltk.stem.porter import *\n",
    "from sklearn import linear_model\n",
    "import operator\n",
    "from math import log\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "def parseData(fname):\n",
    "    for l in urllib.request.urlopen(fname):\n",
    "        yield eval(l)\n",
    "\n",
    "### Just the first 5000 reviews\n",
    "\n",
    "print (\"Reading data...\")\n",
    "data = list(parseData(\"http://jmcauley.ucsd.edu/cse190/data/beer/beer_50000.json\"))[:5000]\n",
    "print (\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36225\n",
      "\n",
      "Total number of unique bigrams: 182902\n",
      "Top 5 bigrams:\n",
      "Bigram ('with', 'a') with count 4587\n",
      "Bigram ('in', 'the') with count 2595\n",
      "Bigram ('of', 'the') with count 2245\n",
      "Bigram ('is', 'a') with count 2056\n",
      "Bigram ('on', 'the') with count 2033\n",
      "\n",
      "MSE of unigram model: 0.48462143628455434\n",
      "\n",
      "MSE of bigram model: 0.0004163648437118068\n"
     ]
    }
   ],
   "source": [
    "### How many unique words are there?\n",
    "\n",
    "wordCount = defaultdict(int)\n",
    "for d in data:\n",
    "    for w in d['review/text'].split():\n",
    "        wordCount[w] += 1\n",
    "\n",
    "print(len(wordCount))\n",
    "\n",
    "### Ignore capitalization and remove punctuation\n",
    "\n",
    "wordCount = defaultdict(int)\n",
    "punctuation = set(string.punctuation)\n",
    "stemmer = PorterStemmer()\n",
    "for d in data:\n",
    "    r = ''.join([c for c in d['review/text'].lower() if not c in punctuation])\n",
    "    for w in r.split():\n",
    "    #w = stemmer.stem(w) # with stemming\n",
    "        wordCount[w] += 1\n",
    "\n",
    "### Just take the most popular words...\n",
    "\n",
    "wordCount = defaultdict(int)\n",
    "punctuation = set(string.punctuation)\n",
    "for d in data:\n",
    "    r = ''.join([c for c in d['review/text'].lower() if not c in punctuation])\n",
    "    for w in r.split():\n",
    "        wordCount[w] += 1\n",
    "\n",
    "counts = [(wordCount[w], w) for w in wordCount]\n",
    "counts.sort()\n",
    "counts.reverse()\n",
    "\n",
    "words = [x[1] for x in counts[:1000]]\n",
    "\n",
    "### Bigram counts\n",
    "translator = str.maketrans(dict.fromkeys(string.punctuation))\n",
    "bigramCount = defaultdict(int)\n",
    "reviewBigramContent = []\n",
    "for d in data:\n",
    "    text = d['review/text']\n",
    "    removed = text.translate(translator)\n",
    "    lowered = removed.lower()\n",
    "    wordList = lowered.split()\n",
    "    prev = None\n",
    "    reviewSet = []\n",
    "    for w in wordList:\n",
    "        if (prev is None):\n",
    "            bigramCount[('/',w)] += 1\n",
    "            reviewSet.append(('/',w))\n",
    "        else:\n",
    "            bigramCount[(prev,w)] += 1\n",
    "            reviewSet.append((prev,w))\n",
    "        prev = w\n",
    "    reviewBigramContent.append(reviewSet)\n",
    "frequentWords = sorted(list(bigramCount.items()), key=operator.itemgetter(1))\n",
    "frequentWords.reverse()\n",
    "bigrams = set(bigramCount.keys())\n",
    "bigramNoDup = list(bigrams)\n",
    "print('')\n",
    "print('Total number of unique bigrams: {}'.format(len(frequentWords)))\n",
    "print('Top 5 bigrams:')\n",
    "for i in range(5):\n",
    "    print('Bigram {} with count {}'.format(frequentWords[i][0],frequentWords[i][1]))\n",
    "\n",
    "wordId = dict(zip(words, range(len(words))))\n",
    "wordSet = set(words)\n",
    "\n",
    "def feature(datum, wordKey):\n",
    "    feat = [0]*len(words)\n",
    "    r = ''.join([c for c in datum['review/text'].lower() if not c in punctuation])\n",
    "    for w in r.split():\n",
    "        if w in words:\n",
    "            feat[wordKey[w]] += 1\n",
    "    feat.append(1) #offset\n",
    "    return feat\n",
    "\n",
    "X = [feature(d,wordId) for d in data]\n",
    "y = [d['review/overall'] for d in data]\n",
    "\n",
    "#No regularization\n",
    "#theta,residuals,rank,s = numpy.linalg.lstsq(X, y)\n",
    "\n",
    "#With regularization\n",
    "clf = linear_model.Ridge(1.0, fit_intercept=False)\n",
    "clf.fit(X, y)\n",
    "theta = clf.coef_\n",
    "predictions = clf.predict(X)\n",
    "err = mean_squared_error(y,predictions)\n",
    "print('\\nMSE of unigram model: {}'.format(err))\n",
    "\n",
    "### Bigram model\n",
    "def featureBi(bigramList,wordKey):\n",
    "    feat = [0] * len(bigrams)\n",
    "    for w in bigramList:\n",
    "        feat[wordKey[w]] += 1\n",
    "    feat.append(1)\n",
    "    return feat\n",
    "wordId = dict(zip(bigramNoDup, range(len(bigramNoDup))))\n",
    "X = [featureBi(d,wordId) for d in reviewBigramContent]\n",
    "y = [d['review/overall'] for d in data]\n",
    "clf = linear_model.Ridge(1.0, fit_intercept=False)\n",
    "clf.fit(X,y)\n",
    "theta = clf.coef_\n",
    "predictions = clf.predict(X)\n",
    "err = mean_squared_error(y,predictions)\n",
    "print('\\nMSE of bigram model: {}'.format(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewsAndWords = []\n",
    "allWords = set()\n",
    "for d in data:\n",
    "    text = d['review/text']\n",
    "    words = ((text.translate(translator)).lower()).split()\n",
    "    reviewsAndWords.append(words)\n",
    "    for w in words:\n",
    "        allWords.add(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkWords = ['foam','smell','banana','lactic','tart']\n",
    "totalDocuments = len(reviewsAndWords)\n",
    "inverseFrequencies = defaultdict(float)\n",
    "for word in allWords:\n",
    "    doc = 0\n",
    "    for rev in reviewsAndWords:\n",
    "        if word in rev:\n",
    "            doc += 1\n",
    "    inverseFrequencies[word] = log(totalDocuments/doc, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDF score for word \"foam\": 1.1378686206869628\n",
      "IDF score for word \"smell\": 0.5379016188648442\n",
      "IDF score for word \"banana\": 1.6777807052660807\n",
      "IDF score for word \"lactic\": 2.920818753952375\n",
      "IDF score for word \"tart\": 1.8068754016455382\n"
     ]
    }
   ],
   "source": [
    "for word in checkWords:\n",
    "    print('IDF score for word \"{}\": {}'.format(word,inverseFrequencies[word]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF score for word \"foam\" in first document: 2.2757372413739256\n",
      "TF-IDF score for word \"smell\" in first document: 0.5379016188648442\n",
      "TF-IDF score for word \"banana\" in first document: 3.3555614105321614\n",
      "TF-IDF score for word \"lactic\" in first document: 5.84163750790475\n",
      "TF-IDF score for word \"tart\" in first document: 1.8068754016455382\n"
     ]
    }
   ],
   "source": [
    "for word in checkWords:\n",
    "    c = reviewsAndWords[0].count(word)\n",
    "    print('TF-IDF score for word \"{}\" in first document: {}'.format(word,c*inverseFrequencies[word]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity of first and second review: 0.0658819397474438\n"
     ]
    }
   ],
   "source": [
    "v1 = []\n",
    "v2 = []\n",
    "for word in allWords:\n",
    "    c1 = reviewsAndWords[0].count(word)\n",
    "    c2 = reviewsAndWords[1].count(word)\n",
    "    v1.append(c1*inverseFrequencies[word])\n",
    "    v2.append(c2*inverseFrequencies[word])\n",
    "def cos_sim(a, b):\n",
    "    \"\"\"Takes 2 vectors a, b and returns the cosine similarity according \n",
    "    to the definition of the dot product\n",
    "    \"\"\"\n",
    "    dot_product = np.dot(a, b)\n",
    "    norm_a = np.linalg.norm(a)\n",
    "    norm_b = np.linalg.norm(b)\n",
    "    if norm_a == 0 or norm_b == 0:\n",
    "        return 0\n",
    "    return dot_product / (norm_a * norm_b)\n",
    "print('Cosine similarity of first and second review: {}'.format(cos_sim(v1,v2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = []\n",
    "for i in range(len(reviewsAndWords)):\n",
    "    v = []\n",
    "    for word in allWords:\n",
    "        c = reviewsAndWords[i].count(word)\n",
    "        v.append(c*inverseFrequencies[word])\n",
    "    vectors.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review with highest cosine similarity to first review has beerId \"72146\" and profileName \"spicelab\"\n"
     ]
    }
   ],
   "source": [
    "v1 = vectors[0]\n",
    "\n",
    "maxCos = 0\n",
    "index = 1\n",
    "maxIndex = -1\n",
    "for v in vectors[1:]:\n",
    "    cos = cos_sim(v1,v)\n",
    "    if cos > maxCos:\n",
    "        maxCos = cos\n",
    "        maxIndex = index\n",
    "    index += 1\n",
    "print('Review with highest cosine similarity to first review has beerId \"{}\" and profileName \"{}\"'.format(data[maxIndex]['beer/beerId'], data[maxIndex]['user/profileName']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
