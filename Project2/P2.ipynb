{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from itertools import combinations\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "done\n",
      "lambda = 1.0:\taccuracy=0.71868\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from urllib.request import urlopen\n",
    "import scipy.optimize\n",
    "import random\n",
    "from math import exp\n",
    "from math import log\n",
    "\n",
    "def parseData(fname):\n",
    "  for l in urlopen(fname):\n",
    "    yield eval(l)\n",
    "\n",
    "print(\"Reading data...\")\n",
    "data = list(parseData(\"http://jmcauley.ucsd.edu/cse190/data/beer/beer_50000.json\"))\n",
    "print(\"done\")\n",
    "\n",
    "def feature(datum):\n",
    "  feat = [1, datum['review/taste'], datum['review/appearance'], datum['review/aroma'], datum['review/palate'], datum['review/overall']]\n",
    "  return feat\n",
    "\n",
    "X = [feature(d) for d in data]\n",
    "y = [d['beer/ABV'] >= 6.5 for d in data]\n",
    "\n",
    "def inner(x,y):\n",
    "  return sum([x[i]*y[i] for i in range(len(x))])\n",
    "\n",
    "def sigmoid(x):\n",
    "  return 1.0 / (1 + exp(-x))\n",
    "\n",
    "##################################################\n",
    "# Logistic regression by gradient ascent         #\n",
    "##################################################\n",
    "\n",
    "# NEGATIVE Log-likelihood\n",
    "def f(theta, X, y, lam):\n",
    "  loglikelihood = 0\n",
    "  for i in range(len(X)):\n",
    "    logit = inner(X[i], theta)\n",
    "    loglikelihood -= log(1 + exp(-logit))\n",
    "    if not y[i]:\n",
    "      loglikelihood -= logit\n",
    "  for k in range(len(theta)):\n",
    "    loglikelihood -= lam * theta[k]*theta[k]\n",
    "  # for debugging\n",
    "  # print(\"ll =\" + str(loglikelihood))\n",
    "  return -loglikelihood\n",
    "\n",
    "# NEGATIVE Derivative of log-likelihood\n",
    "def fprime(theta, X, y, lam):\n",
    "  dl = [0]*len(theta)\n",
    "  for i in range(len(X)):\n",
    "    logit = inner(X[i], theta)\n",
    "    for k in range(len(theta)):\n",
    "      dl[k] += X[i][k] * (1 - sigmoid(logit))\n",
    "      if not y[i]:\n",
    "        dl[k] -= X[i][k]\n",
    "  for k in range(len(theta)):\n",
    "    dl[k] -= lam*2*theta[k]\n",
    "  return numpy.array([-x for x in dl])\n",
    "\n",
    "X_train = X\n",
    "y_train = y\n",
    "\n",
    "##################################################\n",
    "# Train                                          #\n",
    "##################################################\n",
    "\n",
    "def train(lam):\n",
    "  theta,_,_ = scipy.optimize.fmin_l_bfgs_b(f, [0]*len(X[0]), fprime, pgtol = 10, args = (X_train, y_train, lam))\n",
    "  return theta\n",
    "\n",
    "##################################################\n",
    "# Predict                                        #\n",
    "##################################################\n",
    "\n",
    "def performance(theta):\n",
    "    scores = [inner(theta,x) for x in X]\n",
    "    predictions = [s > 0 for s in scores]\n",
    "    correct = [(a==b) for (a,b) in zip(predictions,y_train)]\n",
    "    acc = sum(correct) * 1.0 / len(correct)\n",
    "    return acc\n",
    "\n",
    "##################################################\n",
    "# Validation pipeline                            #\n",
    "##################################################\n",
    "\n",
    "lam = 1.0\n",
    "\n",
    "theta = train(lam)\n",
    "acc = performance(theta)\n",
    "print(\"lambda = \" + str(lam) + \":\\taccuracy=\" + str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of sets: Train 16666, Test 16667, Validate 16667\n",
      "Training performance: 0.7170886835473419\n",
      "Test set performance: 0.7185456290874183\n",
      "Validation set performance: 0.7189056218875622\n"
     ]
    }
   ],
   "source": [
    "#Question 1\n",
    "dataCopy = data.copy()\n",
    "random.shuffle(dataCopy)\n",
    "data_train = dataCopy[:len(dataCopy)//3]\n",
    "data_test = dataCopy[len(dataCopy)//3:round(2*len(dataCopy)/3)]\n",
    "data_valid = dataCopy[round(2*len(dataCopy)/3):]\n",
    "\n",
    "print('Length of sets: Train {}, Test {}, Validate {}'.format(len(data_train), len(data_test), len(data_valid)))\n",
    "\n",
    "X_train = [feature(d) for d in data_train]\n",
    "y_train = [d['beer/ABV'] >= 6.5 for d in data_train]\n",
    "X_test = [feature(d) for d in data_test]\n",
    "y_test = [d['beer/ABV'] >= 6.5 for d in data_test]\n",
    "X_valid = [feature(d) for d in data_valid]\n",
    "y_valid = [d['beer/ABV'] >= 6.5 for d in data_valid]\n",
    "\n",
    "def performance(theta, featureM, labelM):\n",
    "    scores = [inner(theta,x) for x in featureM]\n",
    "    predictions = [s > 0 for s in scores]\n",
    "    correct = [(a==b) for (a,b) in zip(predictions,labelM)]\n",
    "    acc = sum(correct) * 1.0 / len(correct)\n",
    "    return acc\n",
    "\n",
    "theta = train(lam)\n",
    "print('Training performance: {}'.format(performance(theta, X_train, y_train)))\n",
    "print('Test set performance: {}'.format(performance(theta, X_test, y_test)))\n",
    "print('Validation set performance: {}'.format(performance(theta, X_valid, y_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 9113\n",
      "True Negatives: 2863\n",
      "Positives: 12498\n",
      "Negatives: 4169\n",
      "False Positives: 3385\n",
      "False Negatives: 1306\n"
     ]
    }
   ],
   "source": [
    "#Question 2\n",
    "def performance(theta, featureM, labelM, mode='P'):\n",
    "    scores = [inner(theta,x) for x in featureM]\n",
    "    predictions = [s > 0 for s in scores]\n",
    "    if (mode == 'TP'):\n",
    "        correct = sum([(a==b and a == 1) for (a,b) in zip(predictions,labelM)])\n",
    "    if (mode == 'TN'):\n",
    "        correct = sum([(a==b and a == 0) for (a,b) in zip(predictions,labelM)])\n",
    "    if (mode == 'P'):\n",
    "        correct = sum([(a == 1) for (a,b) in zip(predictions,labelM)])\n",
    "    if (mode == 'N'):\n",
    "        correct = sum([(a == 0) for (a,b) in zip(predictions,labelM)])\n",
    "    if (mode == 'FP'):\n",
    "        correct = sum([(a!=b and a == 1) for (a,b) in zip(predictions,labelM)])\n",
    "    if (mode == 'FN'):\n",
    "        correct = sum([(a!=b and a == 0) for (a,b) in zip(predictions,labelM)])\n",
    "    return correct\n",
    "TP = performance(theta, X_test, y_test, 'TP')\n",
    "TN = performance(theta, X_test, y_test, 'TN')\n",
    "P = performance(theta, X_test, y_test, 'P')\n",
    "N = performance(theta, X_test, y_test, 'N')\n",
    "FP = performance(theta, X_test, y_test, 'FP')\n",
    "FN = performance(theta, X_test, y_test, 'FN')\n",
    "print('True Positives: {}'.format(TP))\n",
    "print('True Negatives: {}'.format(TN))\n",
    "print('Positives: {}'.format(P))\n",
    "print('Negatives: {}'.format(N))\n",
    "print('False Positives: {}'.format(FP))\n",
    "print('False Negatives: {}'.format(FN))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7291566650664106\n",
      "Recall: 0.8746520779345427\n",
      "Precision@100: 0.94\n",
      "Recall@100: 1.0\n"
     ]
    }
   ],
   "source": [
    "#Question 3\n",
    "print('Precision: {}'.format(TP/(TP+FP)))\n",
    "print('Recall: {}'.format(TP/(TP+FN)))\n",
    "\n",
    "def PRL(theta, featureM, labelM, limit):\n",
    "    scores = [inner(theta,x) for x in featureM]\n",
    "    sortedScores = sorted(zip(scores, labelM), key=lambda tup:tup[0],reverse=True)\n",
    "    sortedLabels = [i[1] for i in sortedScores]\n",
    "    sortedPreds = [i[0] > 0 for i in sortedScores]\n",
    "    TP = sum([(a==b and a == 1) for (a,b) in zip(sortedPreds[:limit],sortedLabels[:limit])])\n",
    "    FP = correct = sum([(a!=b and a == 1) for (a,b) in zip(sortedPreds[:limit],sortedLabels[:limit])])\n",
    "    FN = correct = sum([(a!=b and a == 0) for (a,b) in zip(sortedPreds[:limit],sortedLabels[:limit])])\n",
    "    if (TP != 0):\n",
    "        return (TP/(TP+FP), TP/(TP+FN))\n",
    "    else:\n",
    "        return(0,0)\n",
    "results = PRL(theta, X_test, y_test, 100)\n",
    "print('Precision@100: {}'.format(results[0]))\n",
    "print('Recall@100: {}'.format(results[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Question 4\n",
    "def PRL(theta, featureM, labelM):\n",
    "    scores = [inner(theta,x) for x in featureM]\n",
    "    sortedScores = sorted(zip(scores, labelM), key=lambda tup:tup[0],reverse=True)\n",
    "    sortedLabels = [i[1] for i in sortedScores]\n",
    "    sortedPreds = [i[0] > 0 for i in sortedScores]\n",
    "    return (sortedPreds, sortedLabels)\n",
    "\n",
    "(preds, labels) = PRL(theta, X_test, y_test)\n",
    "resultP = []\n",
    "resultR = []\n",
    "TP_all = [(a==b and a == 1) for (a,b) in zip(preds,labels)]\n",
    "FP_all = [(a!=b and a == 1) for (a,b) in zip(preds,labels)]\n",
    "FN_all = [(a!=b and a == 0) for (a,b) in zip(preds,labels)]\n",
    "TP = 0\n",
    "TP_sum = sum(TP_all)\n",
    "FP = 0\n",
    "FN = sum(FN_all)\n",
    "for limit in range(len(X_test)):\n",
    "    TP += TP_all[limit]\n",
    "    FP += FP_all[limit]\n",
    "#    FN += FN_all[limit]\n",
    "    if (TP != 0):\n",
    "        resultP.append(TP/(TP+FP))\n",
    "        resultR.append(TP/(TP_sum+FN))\n",
    "    else:\n",
    "        resultP.append(0)\n",
    "        resultR.append(0)\n",
    "plt.plot(resultR, resultP, 'ro')\n",
    "plt.axis([0, 1, 0, 1])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the biggest connected component: 40\n",
      "Connected component:{'863', '876', '886', '774', '769', '825', '804', '819', '889', '811', '772', '893', '798', '745', '719', '800', '708', '856', '840', '888', '861', '869', '697', '753', '884', '805', '880', '810', '823', '882', '864', '729', '830', '803', '703', '890', '713', '747', '828', '878'}\n"
     ]
    }
   ],
   "source": [
    "#Question 5\n",
    "inputF = open('egonet.txt', 'r')\n",
    "G = nx.Graph()\n",
    "nodes = []\n",
    "edges = []\n",
    "for line in inputF.readlines():\n",
    "    both = line.split(' ')\n",
    "    first = both[0]\n",
    "    second = both[1].split('\\n')[0]\n",
    "    nodes.append(first)\n",
    "    nodes.append(second)\n",
    "    edges.append((first,second))\n",
    "uniqueNodes = set(nodes)\n",
    "for node in uniqueNodes:\n",
    "    G.add_node(node)\n",
    "for edge in edges:\n",
    "    G.add_edge(*edge)\n",
    "CCs = list(nx.connected_components(G))\n",
    "\n",
    "maxVal = 0\n",
    "for CC in CCs:\n",
    "    if len(CC) > maxVal:\n",
    "        maxVal = len(CC)\n",
    "        maxCC = CC\n",
    "print('Size of the biggest connected component: {}'.format(maxVal))\n",
    "print('Connected component:{}'.format(maxCC))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized cut cost: 0.8448117539026632\n",
      "First part: ['697', '703', '708', '713', '719', '729', '745', '747', '753', '769', '772', '774', '798', '800', '803', '804', '805', '810', '811', '819']\n",
      "Second part: ['823', '825', '828', '830', '840', '856', '861', '863', '864', '869', '876', '878', '880', '882', '884', '886', '888', '889', '890', '893']\n"
     ]
    }
   ],
   "source": [
    "#Question 6\n",
    "sortedCC = sorted(maxCC)\n",
    "minVals = sortedCC[:round(len(maxCC)/2)]\n",
    "maxVals = sortedCC[round(len(maxCC)/2):]\n",
    "print('Normalized cut cost: {}'.format(nx.normalized_cut_size(G,minVals,maxVals)))\n",
    "print('First part: {}'.format(minVals))\n",
    "print('Second part: {}'.format(maxVals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First split elements: ['697', '703', '708', '713', '719', '745', '747', '753', '769', '772', '774', '798', '800', '803', '805', '810', '811', '819', '828', '823', '830', '840', '880', '890', '869', '856']\n",
      "Second split elements: ['825', '861', '863', '864', '876', '878', '882', '884', '886', '888', '889', '893', '729', '804']\n",
      "Minimum normalized cut cost this split achieves: 0.09817045961624274\n"
     ]
    }
   ],
   "source": [
    "#Question 7\n",
    "minCost = 1.1\n",
    "currentCost = 1.0\n",
    "stable1 = minVals.copy()\n",
    "stable2 = maxVals.copy()\n",
    "while (currentCost < minCost):\n",
    "    minCost = currentCost\n",
    "    minValIter = 1.0\n",
    "    minId = ''\n",
    "    for i in range(len(stable1)):\n",
    "        val = stable1[i]\n",
    "        testCut1 = stable1.copy()\n",
    "        testCut1.remove(val)\n",
    "        testCut2 = stable2.copy()\n",
    "        testCut2.append(val)\n",
    "        cost = nx.normalized_cut_size(G,testCut1,testCut2)/2\n",
    "        if (cost < minValIter):\n",
    "            minId = val\n",
    "            minValIter = cost\n",
    "        if (cost == minValIter and int(minId) > int(val) if minId != '' else True):\n",
    "            minId = val\n",
    "            minValIter = cost\n",
    "            \n",
    "    for i in range(len(stable2)):\n",
    "        val = stable2[i]\n",
    "        testCut1 = stable1.copy()\n",
    "        testCut1.append(val)\n",
    "        testCut2 = stable2.copy()\n",
    "        testCut2.remove(val)\n",
    "        cost = nx.normalized_cut_size(G,testCut1,testCut2)/2\n",
    "        if (cost < minValIter):\n",
    "            minId = val\n",
    "            minValIter = cost\n",
    "        if (cost == minValIter and int(minId) > int(val) if minId != '' else True):\n",
    "            minId = val\n",
    "            minValIter = cost\n",
    "    if minValIter < currentCost:\n",
    "        if (minId in stable1):\n",
    "            stable1.remove(minId)\n",
    "            stable2.append(minId)\n",
    "        else:\n",
    "            stable1.append(minId)\n",
    "            stable2.remove(minId)\n",
    "        currentCost = minValIter\n",
    "print('First split elements: {}'.format(stable1))\n",
    "print('Second split elements: {}'.format(stable2))\n",
    "print('Minimum normalized cut cost this split achieves: {}'.format(nx.normalized_cut_size(G,stable1,stable2)/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial communities: [{'697'}, {'703'}, {'708'}, {'713'}, {'719'}, {'729'}, {'745'}, {'747'}, {'753'}, {'769'}, {'772'}, {'774'}, {'798'}, {'800'}, {'803'}, {'804'}, {'805'}, {'810'}, {'811'}, {'819'}, {'823'}, {'825'}, {'828'}, {'830'}, {'840'}, {'856'}, {'861'}, {'863'}, {'864'}, {'869'}, {'876'}, {'878'}, {'880'}, {'882'}, {'884'}, {'886'}, {'888'}, {'889'}, {'890'}, {'893'}]\n",
      "Communities are enclosed by curly braces\n",
      "Maximum modularity achieved: 0.8144718792866941\n",
      "Maximum modularity communities: [{'863', '876', '886', '769', '774', '825', '804', '819', '889', '811', '772', '893', '798', '745', '719', '800', '708', '856', '840', '888', '861', '869', '697', '753', '884', '805', '880', '810', '823', '882', '864', '729', '830', '803', '890', '703', '713', '747', '828', '878'}]\n"
     ]
    }
   ],
   "source": [
    "#Question 8\n",
    "def modularity(G, communities, weight=None):\n",
    "    def calculateE(c):\n",
    "        edgesOf = list(combinations(c,2))\n",
    "        num_edges = 0\n",
    "        for combo in edgesOf:\n",
    "            num_edges += G.number_of_edges(*combo)\n",
    "        return num_edges/G.number_of_edges()\n",
    "    def calculateA(c):\n",
    "        for node in c:\n",
    "            endpoints = G[node]\n",
    "            num_endpoints = len(endpoints)\n",
    "            if (node in endpoints):\n",
    "                num_endpoints += 1\n",
    "            return num_endpoints/(G.number_of_edges()*2)\n",
    "    Q = 0\n",
    "    for c in communities:\n",
    "        Q += (calculateE(c) - (calculateA(c)**2))\n",
    "    return Q\n",
    "moduleList = [set([i]) for i in sortedCC]\n",
    "currentScore = modularity(G, moduleList)\n",
    "maxScore = -math.inf\n",
    "print('Initial communities: {}'.format(moduleList))\n",
    "while (currentScore > maxScore):\n",
    "    maxScore = currentScore\n",
    "    currentIter = currentScore\n",
    "    for i in range(len(moduleList)):\n",
    "        for j in range(i+1,len(moduleList)):\n",
    "            temp = moduleList.copy()\n",
    "            join1 = moduleList[i]\n",
    "            join2 = moduleList[j]\n",
    "            joined = join1.union(join2)\n",
    "            temp.remove(join1)\n",
    "            temp.remove(join2)\n",
    "            temp.append(joined)\n",
    "            currentVal = modularity(G,temp)\n",
    "            if (currentVal > currentIter):\n",
    "                maxList = temp\n",
    "                currentIter = currentVal\n",
    "    if (currentIter > currentScore):\n",
    "        currentScore = currentIter\n",
    "        moduleList = maxList\n",
    "print('Communities are enclosed by curly braces')\n",
    "print('Maximum modularity achieved: {}'.format(currentScore))\n",
    "print('Maximum modularity communities: {}'.format(moduleList))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
